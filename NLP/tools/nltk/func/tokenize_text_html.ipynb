{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "raw = \"when you try your best but you don't success.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['when', 'you', 'try', 'your', 'best', 'but', 'you', 'do', \"n't\", 'success', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(raw)\n",
    "print(type(tokens))\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: when you try your best but you do...>\n",
      "<class 'nltk.text.Text'>\n",
      "['try', 'your', 'best']\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "### Text\n",
    "text = nltk.Text(tokens)\n",
    "print(text)\n",
    "print(type(text))\n",
    "print(text[2:5])\n",
    "print(text.collocations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "print(raw.find(\"best\")) #获取第一个匹配的索引值 这应该是python里的\n",
    "print(raw.rfind(\"you\")) #反向的find 即包含搜索内容的 最后 一个匹配的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<HTML>\\n<HEAD>\\n   <META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=iso'\n"
     ]
    }
   ],
   "source": [
    "### 处理HTML\n",
    "#from urllib import urlopen   py2\n",
    "from urllib.request import urlopen\n",
    "url = \"http://www.cs.columbia.edu/~mcollins/\"\n",
    "html = urlopen(url).read()\n",
    "print(html[:80])\n",
    "#print(html[:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "To remove HTML markup, use BeautifulSoup's get_text() function",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-cad780b79719>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhtml_clean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml_clean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\a\\software\\python3\\lib\\site-packages\\nltk-3.2.4-py3.5.egg\\nltk\\util.py\u001b[0m in \u001b[0;36mclean_html\u001b[1;34m(html)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclean_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"To remove HTML markup, use BeautifulSoup's get_text() function\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclean_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: To remove HTML markup, use BeautifulSoup's get_text() function"
     ]
    }
   ],
   "source": [
    "html_clean = nltk.clean_html(html)\n",
    "tokens = nltk.word_tokenize(html_clean)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   \n",
      "   \n",
      "   Michael Collins\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Michael Collins\n",
      "Vikram S. Pandit Professor of Computer Science, Columbia University. \n",
      "\n",
      "\n",
      "Office:\n",
      "Room 723,\n",
      "Schapiro \n",
      "CESPR\n",
      "\n",
      "Email:\n",
      "mcollins [at] cs.columbia.[first 3 letters in \"education\"]\n",
      "\n",
      "\n",
      "Mailing Address:\n",
      "\n",
      "Columbia University\n",
      "Department of Computer Science\n",
      "1214 Amsterdam Avenue\n",
      "M/C 0401\n",
      "450 CS Building\n",
      "New York, NY 10027\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I am one of\n",
      "the two editors in chief\n",
      "for a new ACL-sponsored journal,\n",
      "\n",
      "Transactions of the Association for Computational Linguistics\n",
      "(TACL). Please consider submitting a paper!\n",
      "\n",
      "\n",
      " \n",
      "Current teaching (Spring \n",
      "  2015): \n",
      "COMS W4705, Natural Language Processing.\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "Online teaching:\n",
      "In Spring 2013 I taught an \n",
      "\n",
      "online course on Natural Language Processing\n",
      "on \n",
      "\n",
      "Coursera.\n",
      "\n",
      "Notes for the Coursera class are posted\n",
      "here.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Publications\n",
      "(on \n",
      "\n",
      "Google scholar).\n",
      "\n",
      "\n",
      "\n",
      "Bio: \n",
      "My research interests are in natural language processing,\n",
      "and machine learning. I completed a PhD in computer science from the\n",
      "University of Pennsylvania in December 1998. From January 1999 to\n",
      "November 2002 I was a researcher at AT&T Labs-Research, and from\n",
      "January 2003 until December 2010 I was an assistant/associate professor\n",
      "at MIT. I joined Columbia University in January 2011.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Students and Postdocs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Awards: NSF career award, Alfred P. Sloan research fellowship, \n",
      "ACL fellow,\n",
      "faculty finalist for \n",
      "the 2012 Blavatnik\n",
      "award. Best paper\n",
      "awards at EMNLP 2002, EMNLP 2004, UAI 2004, UAI 2005, CoNLL 2008, EMNLP 2010.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "Recently I've been trying to make an effort to write up fairly\n",
      "comprehensive notes for topics I teach in statistical NLP. So far I've\n",
      "covered\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Language models\n",
      "\n",
      "\n",
      "Hidden Markov models and tagging (sequence labeling) problems\n",
      "\n",
      "\n",
      "PCFGs\n",
      "\n",
      "\n",
      "Lexicalized PCFGs\n",
      "\n",
      "\n",
      "IBM Models 1 and 2 for machine \n",
      "translation\n",
      "\n",
      "\n",
      "Phrase-based\n",
      "translation models\n",
      "\n",
      "\n",
      "Log-linear\n",
      "models\n",
      "\n",
      "\n",
      "MEMMs (Log-linear taggers)\n",
      "\n",
      "\n",
      "\n",
      "Log-linear models, MEMMs, and CRFs\n",
      "\n",
      "\n",
      "The forward-backward algorithm\n",
      "\n",
      "\n",
      "The EM algorithm\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The inside-outside algorithm\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Recent teaching:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Fall\n",
      "  2012: \n",
      "COMS W4705, Natural Language Processing.\n",
      "\n",
      "\n",
      "Spring 2012:\n",
      "\n",
      "COMS E6998, Machine learning for natural language processing\n",
      "\n",
      "\n",
      " Fall\n",
      "2011: \n",
      "COMS W4705, Natural Language Processing.\n",
      "\n",
      "\n",
      "\n",
      " Spring 2011:\n",
      "\n",
      "COMS E6998-3, Machine learning for natural language processing\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Software and Data Sets (including source code for\n",
      "my PhD thesis parser).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Past Teaching\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\a\\software\\python3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file d:\\a\\software\\python3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html)\n",
    "print(soup.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Michael', 'Collins', 'Michael', 'Collins', 'Vikram', 'S.', 'Pandit', 'Professor', 'of', 'Computer', 'Science', ',', 'Columbia', 'University', '.', 'Office', ':', 'Room', '723', ',', 'Schapiro', 'CESPR', 'Email', ':', 'mcollins', '[', 'at', ']', 'cs.columbia', '.', '[', 'first', '3', 'letters', 'in', '``', 'education', \"''\", ']', 'Mailing', 'Address', ':', 'Columbia', 'University', 'Department', 'of', 'Computer', 'Science', '1214', 'Amsterdam', 'Avenue', 'M/C', '0401', '450', 'CS', 'Building', 'New', 'York', ',', 'NY', '10027', 'I', 'am', 'one', 'of', 'the', 'two', 'editors', 'in', 'chief', 'for', 'a', 'new', 'ACL-sponsored', 'journal', ',', 'Transactions', 'of', 'the', 'Association', 'for', 'Computational', 'Linguistics', '(', 'TACL', ')', '.', 'Please', 'consider', 'submitting', 'a', 'paper', '!', 'Current', 'teaching', '(', 'Spring', '2015', ')', ':', 'COMS', 'W4705', ',', 'Natural', 'Language', 'Processing', '.', 'Online', 'teaching', ':', 'In', 'Spring', '2013', 'I', 'taught', 'an', 'online', 'course', 'on', 'Natural', 'Language', 'Processing', 'on', 'Coursera', '.', 'Notes', 'for', 'the', 'Coursera', 'class', 'are', 'posted', 'here', '.', 'Publications', '(', 'on', 'Google', 'scholar', ')', '.', 'Bio', ':', 'My', 'research', 'interests', 'are', 'in', 'natural', 'language', 'processing', ',', 'and', 'machine', 'learning', '.', 'I', 'completed', 'a', 'PhD', 'in', 'computer', 'science', 'from', 'the', 'University', 'of', 'Pennsylvania', 'in', 'December', '1998', '.', 'From', 'January', '1999', 'to', 'November', '2002', 'I', 'was', 'a', 'researcher', 'at', 'AT', '&', 'T', 'Labs-Research', ',', 'and', 'from', 'January', '2003', 'until', 'December', '2010', 'I', 'was', 'an', 'assistant/associate', 'professor', 'at', 'MIT', '.', 'I', 'joined', 'Columbia', 'University', 'in', 'January', '2011', '.', 'Students', 'and', 'Postdocs', 'Awards', ':', 'NSF', 'career', 'award', ',', 'Alfred', 'P.', 'Sloan', 'research', 'fellowship', ',', 'ACL', 'fellow', ',', 'faculty', 'finalist', 'for', 'the', '2012', 'Blavatnik', 'award', '.', 'Best', 'paper', 'awards', 'at', 'EMNLP', '2002', ',', 'EMNLP', '2004', ',', 'UAI', '2004', ',', 'UAI', '2005', ',', 'CoNLL', '2008', ',', 'EMNLP', '2010', '.', 'Recently', 'I', \"'ve\", 'been', 'trying', 'to', 'make', 'an', 'effort', 'to', 'write', 'up', 'fairly', 'comprehensive', 'notes', 'for', 'topics', 'I', 'teach', 'in', 'statistical', 'NLP', '.', 'So', 'far', \"I've\", 'covered', 'Language', 'models', 'Hidden', 'Markov', 'models', 'and', 'tagging', '(', 'sequence', 'labeling', ')', 'problems', 'PCFGs', 'Lexicalized', 'PCFGs', 'IBM', 'Models', '1', 'and', '2', 'for', 'machine', 'translation', 'Phrase-based', 'translation', 'models', 'Log-linear', 'models', 'MEMMs', '(', 'Log-linear', 'taggers', ')', 'Log-linear', 'models', ',', 'MEMMs', ',', 'and', 'CRFs', 'The', 'forward-backward', 'algorithm', 'The', 'EM', 'algorithm', 'The', 'inside-outside', 'algorithm', 'Recent', 'teaching', ':', 'Fall', '2012', ':', 'COMS', 'W4705', ',', 'Natural', 'Language', 'Processing', '.', 'Spring', '2012', ':', 'COMS', 'E6998', ',', 'Machine', 'learning', 'for', 'natural', 'language', 'processing', 'Fall', '2011', ':', 'COMS', 'W4705', ',', 'Natural', 'Language', 'Processing', '.', 'Spring', '2011', ':', 'COMS', 'E6998-3', ',', 'Machine', 'learning', 'for', 'natural', 'language', 'processing', 'Software', 'and', 'Data', 'Sets', '(', 'including', 'source', 'code', 'for', 'my', 'PhD', 'thesis', 'parser', ')', '.', 'Past', 'Teaching']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(soup.get_text())\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
