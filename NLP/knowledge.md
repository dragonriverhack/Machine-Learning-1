
## NLP知识点



### 1.word2vec
* CBOW: 训练输入是某一个特征词的上下文相关的词对应的词向量，而输出就是这特定的一个词的词向量。由于CBOW使用的是词袋模型，因此这8个词都是平等的，也就是不考虑他们和我们关注的词之间的距离大小，只要在我们上下文之内即可。
* Skip-Gram: 输入是特定的一个词的词向量，而输出是特定词对应的上下文词向量。

### 2.分词
	中文分词的基本方法可以分为基于语法规则的方法、基于词典的方法和基于统计的方法。
    基于语法规则的分词法基本思想是在分词的同时进行句法、语义分析, 利用句法信息和语义信息来进行词性标注, 以解决分词歧义现象。因为现有的语法知识、句法规则十分笼统、复杂, 基于语法和规则的分词法所能达到的精确度远远还不能令人满意, 目前这种分词系统应用较少。
    在基于词典的方法中，可以进一步分为最大匹配法，最大概率法，最短路径法等。最大匹配法指的是按照一定顺序选取字符串中的若干个字当做一个词，去词典中查找。根据扫描方式可细分为：正向最大匹配，反向最大匹配，双向最大匹配，最小切分。最大概率法指的是一个待切分的汉字串可能包含多种分词结果，将其中概率最大的那个作为该字串的分词结果。最短路径法指的是在词图上选择一条词数最少的路径。
    基于统计的分词法的基本原理是根据字符串在语料库中出现的统计频率来决定其是否构成词。词是字的组合，相邻的字同时出现的次数越多, 就越有可能构成一个词。因此字与字相邻共现的频率或概率能够较好的反映它们成为词的可信度。常用的方法有HMM（隐马尔科夫模型），MAXENT（最大熵模型），MEMM（最大熵隐马尔科夫模型），CRF（条件随机场）。










