{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [机器之心GitHub项目：GAN完整理论推导与实现](https://zhuanlan.zhihu.com/p/29837245)\n",
    "\n",
    "[原notebookGITHUB](https://github.com/jiqizhixin/ML-Tutorial-Experiment/blob/master/Experiments/Keras_GAN.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    #下面搭建生成器的架构，首先导入序贯模型（sequential），即多个网络层的线性堆叠\n",
    "    model = Sequential()\n",
    "    #添加一个全连接层，输入为100维向量，输出为1024维\n",
    "    model.add(Dense(input_dim=100, output_dim=1024))\n",
    "    #添加一个激活函数tanh\n",
    "    model.add(Activation('tanh'))\n",
    "    #添加一个全连接层，输出为128×7×7维度\n",
    "    model.add(Dense(128*7*7))\n",
    "    #添加一个批量归一化层，该层在每个batch上将前一层的激活值重新规范化，即使得其输出数据的均值接近0，其标准差接近1\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    #Reshape层用来将输入shape转换为特定的shape，将含有128*7*7个元素的向量转化为7×7×128张量\n",
    "    model.add(Reshape((7, 7, 128), input_shape=(128*7*7,)))\n",
    "    #2维上采样层，即将数据的行和列分别重复2次\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    #添加一个2维卷积层，卷积核大小为5×5，激活函数为tanh，共64个卷积核，并采用padding以保持图像尺寸不变\n",
    "    model.add(Conv2D(64, (5, 5), padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    #卷积核设为1即输出图像的维度\n",
    "    model.add(Conv2D(1, (5, 5), padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    #下面搭建判别器架构，同样采用序贯模型\n",
    "    model = Sequential()\n",
    "    \n",
    "    #添加2维卷积层，卷积核大小为5×5，激活函数为tanh，输入shape在‘channels_first’模式下为（samples,channels，rows，cols）\n",
    "    #在‘channels_last’模式下为（samples,rows,cols,channels），输出为64维\n",
    "    model.add(\n",
    "            Conv2D(64, (5, 5),\n",
    "            padding='same',\n",
    "            input_shape=(28, 28, 1))\n",
    "            )\n",
    "    model.add(Activation('tanh'))\n",
    "    #为空域信号施加最大值池化，pool_size取（2，2）代表使图片在两个维度上均变为原长的一半\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (5, 5)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #Flatten层把多维输入一维化，常用在从卷积层到全连接层的过渡\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    #一个结点进行二值分类，并采用sigmoid函数的输出作为概念\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(g, d):\n",
    "    #将前面定义的生成器架构和判别器架构组拼接成一个大的神经网络，用于判别生成的图片\n",
    "    model = Sequential()\n",
    "    #先添加生成器架构，再令d不可训练，即固定d\n",
    "    #因此在给定d的情况下训练生成器，即通过将生成的结果投入到判别器进行辨别而优化生成器\n",
    "    model.add(g)\n",
    "    d.trainable = False\n",
    "    model.add(d)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    #生成图片拼接\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[:, :, 0]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对于每一次迭代：\n",
    "\n",
    "-  从真实数据分布 P_data 抽取 m 个样本\n",
    "-  从先验分布 P_prior(z) 抽取 m 个噪声样本\n",
    "-  将噪声样本投入 G 而生成数据，即x^tilde = G(Z^i)；通过最大化 V 的近似而更新判别器参数θ_d\n",
    "\n",
    "以上是学习判别器 D 的过程。因为学习 D 的过程是计算 JS 散度的过程，并且我们希望能最大化价值函数，所以该步骤会重复 k 次。\n",
    "\n",
    "-  从先验分布 P_prior(z) 中抽取另外 m 个噪声样本 {z^1,...,z^m}\n",
    "-  通过极小化 V^tilde 而更新生成器参数θ_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(BATCH_SIZE):\n",
    "    \n",
    "    # 国内好像不能直接导入数据集，我们试了几次都不行，后来将数据集下载到本地'~/.keras/datasets/'，也就是当前目录（我的是用户文件夹下）下的.keras文件夹中。\n",
    "    #下载的地址为：https://s3.amazonaws.com/img-datasets/mnist.npz\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    #iamge_data_format选择\"channels_last\"或\"channels_first\"，该选项指定了Keras将要使用的维度顺序。\n",
    "    #\"channels_first\"假定2D数据的维度顺序为(channels, rows, cols)，3D数据的维度顺序为(channels, conv_dim1, conv_dim2, conv_dim3)\n",
    "    \n",
    "    #转换字段类型，并将数据导入变量中\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    X_train = X_train[:, :, :, None]\n",
    "    X_test = X_test[:, :, :, None]\n",
    "    # X_train = X_train.reshape((X_train.shape, 1) + X_train.shape[1:])\n",
    "    \n",
    "    #将定义好的模型架构赋值给特定的变量\n",
    "    d = discriminator_model()\n",
    "    g = generator_model()\n",
    "    d_on_g = generator_containing_discriminator(g, d)\n",
    "    \n",
    "    #定义生成器模型判别器模型更新所使用的优化算法及超参数\n",
    "    d_optim = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "    g_optim = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    #编译三个神经网络并设置损失函数和优化算法，其中损失函数都是用的是二元分类交叉熵函数。编译是用来配置模型学习过程的\n",
    "    g.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    d_on_g.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "    \n",
    "    #前一个架构在固定判别器的情况下训练了生成器，所以在训练判别器之前先要设定其为可训练。\n",
    "    d.trainable = True\n",
    "    d.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "    \n",
    "    #下面在满足epoch条件下进行训练\n",
    "    for epoch in range(30):\n",
    "        print(\"Epoch is\", epoch)\n",
    "        \n",
    "        #计算一个epoch所需要的迭代数量，即训练样本数除批量大小数的值取整；其中shape[0]就是读取矩阵第一维度的长度\n",
    "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "        \n",
    "        #在一个epoch内进行迭代训练\n",
    "        for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
    "            \n",
    "            #随机生成的噪声服从均匀分布，且采样下界为-1、采样上界为1，输出BATCH_SIZE×100个样本；即抽取一个批量的随机样本\n",
    "            noise = np.random.uniform(-1, 1, size=(BATCH_SIZE, 100))\n",
    "            \n",
    "            #抽取一个批量的真实图片\n",
    "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            \n",
    "            #生成的图片使用生成器对随机噪声进行推断；verbose为日志显示，0为不在标准输出流输出日志信息，1为输出进度条记录\n",
    "            generated_images = g.predict(noise, verbose=0)\n",
    "            \n",
    "            #每经过100次迭代输出一张生成的图片\n",
    "            if index % 100 == 0:\n",
    "                image = combine_images(generated_images)\n",
    "                image = image*127.5+127.5\n",
    "                Image.fromarray(image.astype(np.uint8)).save(\"./GAN/\"+str(epoch)+\"_\"+str(index)+\".png\")\n",
    "            \n",
    "            #将真实的图片和生成的图片以多维数组的形式拼接在一起，真实图片在上，生成图片在下\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            \n",
    "            #生成图片真假标签，即一个包含两倍批量大小的列表；前一个批量大小都是1，代表真实图片，后一个批量大小都是0，代表伪造图片\n",
    "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "            \n",
    "            #判别器的损失；在一个batch的数据上进行一次参数更新\n",
    "            d_loss = d.train_on_batch(X, y)\n",
    "            print(\"batch %d d_loss : %f\" % (index, d_loss))\n",
    "            \n",
    "            #随机生成的噪声服从均匀分布\n",
    "            noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
    "            \n",
    "            #固定判别器\n",
    "            d.trainable = False\n",
    "            \n",
    "            #计算生成器损失；在一个batch的数据上进行一次参数更新\n",
    "            g_loss = d_on_g.train_on_batch(noise, [1] * BATCH_SIZE)\n",
    "            \n",
    "            #令判别器可训练\n",
    "            d.trainable = True\n",
    "            print(\"batch %d g_loss : %f\" % (index, g_loss))\n",
    "            \n",
    "            #每100次迭代保存一次生成器和判别器的权重\n",
    "            if index % 100 == 9:\n",
    "                g.save_weights('generator', True)\n",
    "                d.save_weights('discriminator', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\software\\python\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1024, input_dim=100)`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 0\n",
      "Number of batches 468\n",
      "batch 0 d_loss : 0.651978\n",
      "batch 0 g_loss : 0.653149\n",
      "batch 1 d_loss : 0.639725\n",
      "batch 1 g_loss : 0.645179\n",
      "batch 2 d_loss : 0.624481\n",
      "batch 2 g_loss : 0.633186\n",
      "batch 3 d_loss : 0.600257\n",
      "batch 3 g_loss : 0.619147\n",
      "batch 4 d_loss : 0.581192\n",
      "batch 4 g_loss : 0.603321\n",
      "batch 5 d_loss : 0.554355\n",
      "batch 5 g_loss : 0.597126\n",
      "batch 6 d_loss : 0.537645\n",
      "batch 6 g_loss : 0.584211\n",
      "batch 7 d_loss : 0.520177\n",
      "batch 7 g_loss : 0.567349\n",
      "batch 8 d_loss : 0.503279\n",
      "batch 8 g_loss : 0.559891\n",
      "batch 9 d_loss : 0.493053\n",
      "batch 9 g_loss : 0.545466\n",
      "batch 10 d_loss : 0.484570\n",
      "batch 10 g_loss : 0.540249\n",
      "batch 11 d_loss : 0.469190\n",
      "batch 11 g_loss : 0.531435\n",
      "batch 12 d_loss : 0.463894\n",
      "batch 12 g_loss : 0.526381\n",
      "batch 13 d_loss : 0.453370\n",
      "batch 13 g_loss : 0.520574\n",
      "batch 14 d_loss : 0.458233\n",
      "batch 14 g_loss : 0.508590\n",
      "batch 15 d_loss : 0.457384\n",
      "batch 15 g_loss : 0.507561\n",
      "batch 16 d_loss : 0.458243\n",
      "batch 16 g_loss : 0.506943\n",
      "batch 17 d_loss : 0.461206\n",
      "batch 17 g_loss : 0.498258\n",
      "batch 18 d_loss : 0.458951\n",
      "batch 18 g_loss : 0.497975\n",
      "batch 19 d_loss : 0.460366\n",
      "batch 19 g_loss : 0.497394\n",
      "batch 20 d_loss : 0.463955\n",
      "batch 20 g_loss : 0.496585\n",
      "batch 21 d_loss : 0.478680\n",
      "batch 21 g_loss : 0.500596\n",
      "batch 22 d_loss : 0.477412\n",
      "batch 22 g_loss : 0.500952\n",
      "batch 23 d_loss : 0.479661\n",
      "batch 23 g_loss : 0.506071\n",
      "batch 24 d_loss : 0.487687\n",
      "batch 24 g_loss : 0.509279\n",
      "batch 25 d_loss : 0.491930\n",
      "batch 25 g_loss : 0.517566\n",
      "batch 26 d_loss : 0.499258\n",
      "batch 26 g_loss : 0.529529\n",
      "batch 27 d_loss : 0.498764\n",
      "batch 27 g_loss : 0.534673\n",
      "batch 28 d_loss : 0.514322\n",
      "batch 28 g_loss : 0.545454\n",
      "batch 29 d_loss : 0.509265\n",
      "batch 29 g_loss : 0.557002\n",
      "batch 30 d_loss : 0.507164\n",
      "batch 30 g_loss : 0.570490\n",
      "batch 31 d_loss : 0.502942\n",
      "batch 31 g_loss : 0.584526\n",
      "batch 32 d_loss : 0.503026\n",
      "batch 32 g_loss : 0.601911\n",
      "batch 33 d_loss : 0.498786\n",
      "batch 33 g_loss : 0.621503\n",
      "batch 34 d_loss : 0.491122\n",
      "batch 34 g_loss : 0.647376\n",
      "batch 35 d_loss : 0.493958\n",
      "batch 35 g_loss : 0.666375\n",
      "batch 36 d_loss : 0.486555\n",
      "batch 36 g_loss : 0.677024\n",
      "batch 37 d_loss : 0.490598\n",
      "batch 37 g_loss : 0.702301\n",
      "batch 38 d_loss : 0.479216\n",
      "batch 38 g_loss : 0.724128\n",
      "batch 39 d_loss : 0.460473\n",
      "batch 39 g_loss : 0.743823\n",
      "batch 40 d_loss : 0.452565\n",
      "batch 40 g_loss : 0.766780\n",
      "batch 41 d_loss : 0.448236\n",
      "batch 41 g_loss : 0.786691\n",
      "batch 42 d_loss : 0.430913\n",
      "batch 42 g_loss : 0.807230\n",
      "batch 43 d_loss : 0.423315\n",
      "batch 43 g_loss : 0.835815\n",
      "batch 44 d_loss : 0.417507\n",
      "batch 44 g_loss : 0.845341\n",
      "batch 45 d_loss : 0.403215\n",
      "batch 45 g_loss : 0.870644\n",
      "batch 46 d_loss : 0.385112\n",
      "batch 46 g_loss : 0.897859\n",
      "batch 47 d_loss : 0.379941\n",
      "batch 47 g_loss : 0.904820\n",
      "batch 48 d_loss : 0.355749\n",
      "batch 48 g_loss : 0.920744\n",
      "batch 49 d_loss : 0.343687\n",
      "batch 49 g_loss : 0.951370\n",
      "batch 50 d_loss : 0.360444\n",
      "batch 50 g_loss : 0.963526\n",
      "batch 51 d_loss : 0.344005\n",
      "batch 51 g_loss : 0.975336\n",
      "batch 52 d_loss : 0.367004\n",
      "batch 52 g_loss : 0.969377\n",
      "batch 53 d_loss : 0.338722\n",
      "batch 53 g_loss : 0.995278\n",
      "batch 54 d_loss : 0.305909\n",
      "batch 54 g_loss : 1.006042\n",
      "batch 55 d_loss : 0.321450\n",
      "batch 55 g_loss : 0.991857\n",
      "batch 56 d_loss : 0.317789\n",
      "batch 56 g_loss : 0.991946\n",
      "batch 57 d_loss : 0.334254\n",
      "batch 57 g_loss : 0.982500\n",
      "batch 58 d_loss : 0.283560\n",
      "batch 58 g_loss : 0.972398\n",
      "batch 59 d_loss : 0.282289\n",
      "batch 59 g_loss : 0.963740\n",
      "batch 60 d_loss : 0.255579\n",
      "batch 60 g_loss : 0.947041\n",
      "batch 61 d_loss : 0.240404\n",
      "batch 61 g_loss : 0.951862\n",
      "batch 62 d_loss : 0.227480\n",
      "batch 62 g_loss : 0.934585\n",
      "batch 63 d_loss : 0.241406\n",
      "batch 63 g_loss : 0.886513\n",
      "batch 64 d_loss : 0.225044\n",
      "batch 64 g_loss : 0.903171\n",
      "batch 65 d_loss : 0.215141\n",
      "batch 65 g_loss : 0.868710\n",
      "batch 66 d_loss : 0.189133\n",
      "batch 66 g_loss : 0.866052\n",
      "batch 67 d_loss : 0.195414\n",
      "batch 67 g_loss : 0.859889\n",
      "batch 68 d_loss : 0.195416\n",
      "batch 68 g_loss : 0.831982\n",
      "batch 69 d_loss : 0.204376\n",
      "batch 69 g_loss : 0.813571\n",
      "batch 70 d_loss : 0.217095\n",
      "batch 70 g_loss : 0.797971\n",
      "batch 71 d_loss : 0.231119\n",
      "batch 71 g_loss : 0.786891\n",
      "batch 72 d_loss : 0.229786\n",
      "batch 72 g_loss : 0.763403\n",
      "batch 73 d_loss : 0.215635\n",
      "batch 73 g_loss : 0.740126\n",
      "batch 74 d_loss : 0.221949\n",
      "batch 74 g_loss : 0.695809\n",
      "batch 75 d_loss : 0.212408\n",
      "batch 75 g_loss : 0.659119\n",
      "batch 76 d_loss : 0.204576\n",
      "batch 76 g_loss : 0.661897\n",
      "batch 77 d_loss : 0.228740\n",
      "batch 77 g_loss : 0.647830\n",
      "batch 78 d_loss : 0.225204\n",
      "batch 78 g_loss : 0.591355\n",
      "batch 79 d_loss : 0.227967\n",
      "batch 79 g_loss : 0.584776\n",
      "batch 80 d_loss : 0.233999\n",
      "batch 80 g_loss : 0.576273\n",
      "batch 81 d_loss : 0.242758\n",
      "batch 81 g_loss : 0.554141\n",
      "batch 82 d_loss : 0.256881\n",
      "batch 82 g_loss : 0.563921\n",
      "batch 83 d_loss : 0.289938\n",
      "batch 83 g_loss : 0.548374\n",
      "batch 84 d_loss : 0.261268\n",
      "batch 84 g_loss : 0.527685\n",
      "batch 85 d_loss : 0.282691\n",
      "batch 85 g_loss : 0.527692\n",
      "batch 86 d_loss : 0.297716\n",
      "batch 86 g_loss : 0.539331\n",
      "batch 87 d_loss : 0.311791\n",
      "batch 87 g_loss : 0.506019\n",
      "batch 88 d_loss : 0.340485\n",
      "batch 88 g_loss : 0.519763\n",
      "batch 89 d_loss : 0.343735\n",
      "batch 89 g_loss : 0.535995\n",
      "batch 90 d_loss : 0.351085\n",
      "batch 90 g_loss : 0.546354\n",
      "batch 91 d_loss : 0.344933\n",
      "batch 91 g_loss : 0.535152\n",
      "batch 92 d_loss : 0.355374\n",
      "batch 92 g_loss : 0.581560\n",
      "batch 93 d_loss : 0.346072\n",
      "batch 93 g_loss : 0.603469\n",
      "batch 94 d_loss : 0.377572\n",
      "batch 94 g_loss : 0.665049\n",
      "batch 95 d_loss : 0.342370\n",
      "batch 95 g_loss : 0.663438\n",
      "batch 96 d_loss : 0.362433\n",
      "batch 96 g_loss : 0.759898\n",
      "batch 97 d_loss : 0.327359\n",
      "batch 97 g_loss : 0.812662\n",
      "batch 98 d_loss : 0.318446\n",
      "batch 98 g_loss : 0.898595\n",
      "batch 99 d_loss : 0.324448\n",
      "batch 99 g_loss : 0.919033\n",
      "batch 100 d_loss : 0.302690\n",
      "batch 100 g_loss : 1.042299\n",
      "batch 101 d_loss : 0.234499\n",
      "batch 101 g_loss : 1.135323\n",
      "batch 102 d_loss : 0.224226\n",
      "batch 102 g_loss : 1.276195\n",
      "batch 103 d_loss : 0.215773\n",
      "batch 103 g_loss : 1.368236\n",
      "batch 104 d_loss : 0.186593\n",
      "batch 104 g_loss : 1.409645\n",
      "batch 105 d_loss : 0.169177\n",
      "batch 105 g_loss : 1.602849\n",
      "batch 106 d_loss : 0.165936\n",
      "batch 106 g_loss : 1.738078\n",
      "batch 107 d_loss : 0.160248\n",
      "batch 107 g_loss : 1.757777\n",
      "batch 108 d_loss : 0.150480\n",
      "batch 108 g_loss : 1.889463\n",
      "batch 109 d_loss : 0.140270\n",
      "batch 109 g_loss : 1.899595\n",
      "batch 110 d_loss : 0.136118\n",
      "batch 110 g_loss : 1.974368\n",
      "batch 111 d_loss : 0.132988\n",
      "batch 111 g_loss : 1.992840\n",
      "batch 112 d_loss : 0.138669\n",
      "batch 112 g_loss : 2.111644\n",
      "batch 113 d_loss : 0.150187\n",
      "batch 113 g_loss : 2.102250\n",
      "batch 114 d_loss : 0.175441\n",
      "batch 114 g_loss : 2.082033\n",
      "batch 115 d_loss : 0.193762\n",
      "batch 115 g_loss : 2.073299\n",
      "batch 116 d_loss : 0.202848\n",
      "batch 116 g_loss : 2.084697\n",
      "batch 117 d_loss : 0.227472\n",
      "batch 117 g_loss : 2.084924\n",
      "batch 118 d_loss : 0.247344\n",
      "batch 118 g_loss : 2.085625\n",
      "batch 119 d_loss : 0.251137\n",
      "batch 119 g_loss : 2.149496\n",
      "batch 120 d_loss : 0.256228\n",
      "batch 120 g_loss : 2.212898\n",
      "batch 121 d_loss : 0.291522\n",
      "batch 121 g_loss : 2.322523\n",
      "batch 122 d_loss : 0.282880\n",
      "batch 122 g_loss : 2.397078\n",
      "batch 123 d_loss : 0.299618\n",
      "batch 123 g_loss : 2.459222\n",
      "batch 124 d_loss : 0.270965\n",
      "batch 124 g_loss : 2.410446\n",
      "batch 125 d_loss : 0.259036\n",
      "batch 125 g_loss : 2.404532\n",
      "batch 126 d_loss : 0.277571\n",
      "batch 126 g_loss : 2.298615\n",
      "batch 127 d_loss : 0.303832\n",
      "batch 127 g_loss : 2.141274\n",
      "batch 128 d_loss : 0.292943\n",
      "batch 128 g_loss : 1.985821\n",
      "batch 129 d_loss : 0.326044\n",
      "batch 129 g_loss : 1.742002\n",
      "batch 130 d_loss : 0.283716\n",
      "batch 130 g_loss : 1.513345\n",
      "batch 131 d_loss : 0.324443\n",
      "batch 131 g_loss : 1.340775\n",
      "batch 132 d_loss : 0.254875\n",
      "batch 132 g_loss : 1.320838\n",
      "batch 133 d_loss : 0.280140\n",
      "batch 133 g_loss : 1.177621\n",
      "batch 134 d_loss : 0.212417\n",
      "batch 134 g_loss : 1.165488\n",
      "batch 135 d_loss : 0.216965\n",
      "batch 135 g_loss : 1.093810\n",
      "batch 136 d_loss : 0.231314\n",
      "batch 136 g_loss : 1.086415\n",
      "batch 137 d_loss : 0.274876\n",
      "batch 137 g_loss : 1.013032\n",
      "batch 138 d_loss : 0.183653\n",
      "batch 138 g_loss : 0.869480\n",
      "batch 139 d_loss : 0.167217\n",
      "batch 139 g_loss : 0.852885\n",
      "batch 140 d_loss : 0.146274\n",
      "batch 140 g_loss : 0.859637\n",
      "batch 141 d_loss : 0.127139\n",
      "batch 141 g_loss : 0.882115\n",
      "batch 142 d_loss : 0.133477\n",
      "batch 142 g_loss : 0.888828\n",
      "batch 143 d_loss : 0.131044\n",
      "batch 143 g_loss : 0.929020\n",
      "batch 144 d_loss : 0.138895\n",
      "batch 144 g_loss : 0.790317\n",
      "batch 145 d_loss : 0.156914\n",
      "batch 145 g_loss : 0.690647\n",
      "batch 146 d_loss : 0.175136\n",
      "batch 146 g_loss : 0.684229\n",
      "batch 147 d_loss : 0.176215\n",
      "batch 147 g_loss : 0.615385\n",
      "batch 148 d_loss : 0.176579\n",
      "batch 148 g_loss : 0.661227\n",
      "batch 149 d_loss : 0.172776\n",
      "batch 149 g_loss : 0.620744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 150 d_loss : 0.167415\n",
      "batch 150 g_loss : 0.651569\n",
      "batch 151 d_loss : 0.137605\n",
      "batch 151 g_loss : 0.665578\n",
      "batch 152 d_loss : 0.173832\n",
      "batch 152 g_loss : 0.636862\n",
      "batch 153 d_loss : 0.166983\n",
      "batch 153 g_loss : 0.692957\n",
      "batch 154 d_loss : 0.196354\n",
      "batch 154 g_loss : 0.675350\n",
      "batch 155 d_loss : 0.231310\n",
      "batch 155 g_loss : 0.722934\n",
      "batch 156 d_loss : 0.242196\n",
      "batch 156 g_loss : 0.643948\n",
      "batch 157 d_loss : 0.230547\n",
      "batch 157 g_loss : 0.592723\n",
      "batch 158 d_loss : 0.274976\n",
      "batch 158 g_loss : 0.459430\n",
      "batch 159 d_loss : 0.269870\n",
      "batch 159 g_loss : 0.470483\n",
      "batch 160 d_loss : 0.263416\n",
      "batch 160 g_loss : 0.539096\n",
      "batch 161 d_loss : 0.268544\n",
      "batch 161 g_loss : 0.704852\n",
      "batch 162 d_loss : 0.343421\n",
      "batch 162 g_loss : 0.596352\n",
      "batch 163 d_loss : 0.365035\n",
      "batch 163 g_loss : 0.710933\n",
      "batch 164 d_loss : 0.514752\n",
      "batch 164 g_loss : 0.526133\n",
      "batch 165 d_loss : 0.479948\n",
      "batch 165 g_loss : 0.599979\n",
      "batch 166 d_loss : 0.506345\n",
      "batch 166 g_loss : 0.443901\n",
      "batch 167 d_loss : 0.550222\n",
      "batch 167 g_loss : 0.456794\n",
      "batch 168 d_loss : 0.574557\n",
      "batch 168 g_loss : 0.461571\n",
      "batch 169 d_loss : 0.712381\n",
      "batch 169 g_loss : 0.520125\n",
      "batch 170 d_loss : 0.508967\n",
      "batch 170 g_loss : 0.465213\n",
      "batch 171 d_loss : 0.549392\n",
      "batch 171 g_loss : 0.714402\n",
      "batch 172 d_loss : 0.770635\n",
      "batch 172 g_loss : 0.628694\n",
      "batch 173 d_loss : 0.729713\n",
      "batch 173 g_loss : 0.593502\n",
      "batch 174 d_loss : 0.663354\n",
      "batch 174 g_loss : 0.608251\n",
      "batch 175 d_loss : 0.661820\n",
      "batch 175 g_loss : 0.500587\n",
      "batch 176 d_loss : 0.679484\n",
      "batch 176 g_loss : 0.581201\n",
      "batch 177 d_loss : 0.556985\n",
      "batch 177 g_loss : 0.796153\n",
      "batch 178 d_loss : 0.688611\n",
      "batch 178 g_loss : 0.725646\n",
      "batch 179 d_loss : 0.675744\n",
      "batch 179 g_loss : 0.729610\n",
      "batch 180 d_loss : 0.634228\n",
      "batch 180 g_loss : 0.829535\n",
      "batch 181 d_loss : 0.704556\n",
      "batch 181 g_loss : 0.841639\n",
      "batch 182 d_loss : 0.661000\n",
      "batch 182 g_loss : 0.864499\n",
      "batch 183 d_loss : 0.678766\n",
      "batch 183 g_loss : 0.819471\n",
      "batch 184 d_loss : 0.749304\n",
      "batch 184 g_loss : 0.790997\n",
      "batch 185 d_loss : 0.683562\n",
      "batch 185 g_loss : 0.717924\n",
      "batch 186 d_loss : 0.674206\n",
      "batch 186 g_loss : 0.671381\n",
      "batch 187 d_loss : 0.554410\n",
      "batch 187 g_loss : 0.801011\n",
      "batch 188 d_loss : 0.578637\n",
      "batch 188 g_loss : 0.883737\n",
      "batch 189 d_loss : 0.619178\n",
      "batch 189 g_loss : 0.976865\n",
      "batch 190 d_loss : 0.598549\n",
      "batch 190 g_loss : 0.907550\n",
      "batch 191 d_loss : 0.578688\n",
      "batch 191 g_loss : 1.011997\n",
      "batch 192 d_loss : 0.531657\n",
      "batch 192 g_loss : 1.047509\n",
      "batch 193 d_loss : 0.500672\n",
      "batch 193 g_loss : 1.054512\n",
      "batch 194 d_loss : 0.550427\n",
      "batch 194 g_loss : 1.061078\n",
      "batch 195 d_loss : 0.544685\n",
      "batch 195 g_loss : 1.035955\n",
      "batch 196 d_loss : 0.500954\n",
      "batch 196 g_loss : 1.111436\n",
      "batch 197 d_loss : 0.476904\n",
      "batch 197 g_loss : 1.206208\n",
      "batch 198 d_loss : 0.439084\n",
      "batch 198 g_loss : 1.213331\n",
      "batch 199 d_loss : 0.471766\n",
      "batch 199 g_loss : 1.236843\n",
      "batch 200 d_loss : 0.474608\n",
      "batch 200 g_loss : 1.278779\n",
      "batch 201 d_loss : 0.478577\n",
      "batch 201 g_loss : 1.185710\n",
      "batch 202 d_loss : 0.472797\n",
      "batch 202 g_loss : 1.152432\n",
      "batch 203 d_loss : 0.468280\n",
      "batch 203 g_loss : 1.203105\n",
      "batch 204 d_loss : 0.472396\n",
      "batch 204 g_loss : 1.257513\n",
      "batch 205 d_loss : 0.462523\n",
      "batch 205 g_loss : 1.250979\n",
      "batch 206 d_loss : 0.486594\n",
      "batch 206 g_loss : 1.207581\n",
      "batch 207 d_loss : 0.475745\n",
      "batch 207 g_loss : 1.233393\n",
      "batch 208 d_loss : 0.455021\n",
      "batch 208 g_loss : 1.227515\n",
      "batch 209 d_loss : 0.462907\n",
      "batch 209 g_loss : 1.204726\n",
      "batch 210 d_loss : 0.458116\n",
      "batch 210 g_loss : 1.202033\n",
      "batch 211 d_loss : 0.467817\n",
      "batch 211 g_loss : 1.233322\n",
      "batch 212 d_loss : 0.469758\n",
      "batch 212 g_loss : 1.233964\n",
      "batch 213 d_loss : 0.484920\n",
      "batch 213 g_loss : 1.181309\n",
      "batch 214 d_loss : 0.479836\n",
      "batch 214 g_loss : 1.178036\n",
      "batch 215 d_loss : 0.482901\n",
      "batch 215 g_loss : 1.126978\n",
      "batch 216 d_loss : 0.474972\n",
      "batch 216 g_loss : 1.172058\n",
      "batch 217 d_loss : 0.474729\n",
      "batch 217 g_loss : 1.123028\n",
      "batch 218 d_loss : 0.494864\n",
      "batch 218 g_loss : 1.138605\n",
      "batch 219 d_loss : 0.497566\n",
      "batch 219 g_loss : 1.141730\n",
      "batch 220 d_loss : 0.508348\n",
      "batch 220 g_loss : 1.087453\n",
      "batch 221 d_loss : 0.536519\n",
      "batch 221 g_loss : 1.027814\n",
      "batch 222 d_loss : 0.508960\n",
      "batch 222 g_loss : 0.963110\n",
      "batch 223 d_loss : 0.511695\n",
      "batch 223 g_loss : 0.888997\n",
      "batch 224 d_loss : 0.471066\n",
      "batch 224 g_loss : 0.909660\n",
      "batch 225 d_loss : 0.502413\n",
      "batch 225 g_loss : 0.837348\n",
      "batch 226 d_loss : 0.456283\n",
      "batch 226 g_loss : 0.947743\n",
      "batch 227 d_loss : 0.449423\n",
      "batch 227 g_loss : 0.887206\n",
      "batch 228 d_loss : 0.467633\n",
      "batch 228 g_loss : 0.911004\n",
      "batch 229 d_loss : 0.429781\n",
      "batch 229 g_loss : 0.885003\n",
      "batch 230 d_loss : 0.416388\n",
      "batch 230 g_loss : 0.893807\n",
      "batch 231 d_loss : 0.440517\n",
      "batch 231 g_loss : 0.889896\n",
      "batch 232 d_loss : 0.471199\n",
      "batch 232 g_loss : 0.723049\n",
      "batch 233 d_loss : 0.485616\n",
      "batch 233 g_loss : 0.679585\n",
      "batch 234 d_loss : 0.486514\n",
      "batch 234 g_loss : 0.701495\n",
      "batch 235 d_loss : 0.513314\n",
      "batch 235 g_loss : 0.657436\n",
      "batch 236 d_loss : 0.434823\n",
      "batch 236 g_loss : 0.758759\n",
      "batch 237 d_loss : 0.421331\n",
      "batch 237 g_loss : 0.772215\n",
      "batch 238 d_loss : 0.445008\n",
      "batch 238 g_loss : 0.793373\n",
      "batch 239 d_loss : 0.509714\n",
      "batch 239 g_loss : 0.691313\n",
      "batch 240 d_loss : 0.470966\n",
      "batch 240 g_loss : 0.629582\n",
      "batch 241 d_loss : 0.442284\n",
      "batch 241 g_loss : 0.640907\n",
      "batch 242 d_loss : 0.459207\n",
      "batch 242 g_loss : 0.704162\n",
      "batch 243 d_loss : 0.510808\n",
      "batch 243 g_loss : 0.686847\n",
      "batch 244 d_loss : 0.497786\n",
      "batch 244 g_loss : 0.665604\n",
      "batch 245 d_loss : 0.525090\n",
      "batch 245 g_loss : 0.649198\n",
      "batch 246 d_loss : 0.498728\n",
      "batch 246 g_loss : 0.641615\n",
      "batch 247 d_loss : 0.516236\n",
      "batch 247 g_loss : 0.636573\n",
      "batch 248 d_loss : 0.525957\n",
      "batch 248 g_loss : 0.595401\n",
      "batch 249 d_loss : 0.473591\n",
      "batch 249 g_loss : 0.661875\n",
      "batch 250 d_loss : 0.454688\n",
      "batch 250 g_loss : 0.761512\n",
      "batch 251 d_loss : 0.570140\n",
      "batch 251 g_loss : 0.683029\n",
      "batch 252 d_loss : 0.553993\n",
      "batch 252 g_loss : 0.717728\n",
      "batch 253 d_loss : 0.594316\n",
      "batch 253 g_loss : 0.712105\n",
      "batch 254 d_loss : 0.562553\n",
      "batch 254 g_loss : 0.673620\n",
      "batch 255 d_loss : 0.528966\n",
      "batch 255 g_loss : 0.649351\n",
      "batch 256 d_loss : 0.522912\n",
      "batch 256 g_loss : 0.651230\n",
      "batch 257 d_loss : 0.462844\n",
      "batch 257 g_loss : 0.796586\n",
      "batch 258 d_loss : 0.580838\n",
      "batch 258 g_loss : 0.758533\n",
      "batch 259 d_loss : 0.510085\n",
      "batch 259 g_loss : 0.750590\n",
      "batch 260 d_loss : 0.618431\n",
      "batch 260 g_loss : 0.638645\n",
      "batch 261 d_loss : 0.585528\n",
      "batch 261 g_loss : 0.655175\n",
      "batch 262 d_loss : 0.607257\n",
      "batch 262 g_loss : 0.681319\n",
      "batch 263 d_loss : 0.562244\n",
      "batch 263 g_loss : 0.736983\n",
      "batch 264 d_loss : 0.539482\n",
      "batch 264 g_loss : 0.827283\n",
      "batch 265 d_loss : 0.609757\n",
      "batch 265 g_loss : 0.769566\n",
      "batch 266 d_loss : 0.576262\n",
      "batch 266 g_loss : 0.732446\n",
      "batch 267 d_loss : 0.557886\n",
      "batch 267 g_loss : 0.786919\n",
      "batch 268 d_loss : 0.534492\n",
      "batch 268 g_loss : 0.895064\n",
      "batch 269 d_loss : 0.532592\n",
      "batch 269 g_loss : 0.922218\n",
      "batch 270 d_loss : 0.562467\n",
      "batch 270 g_loss : 0.923015\n",
      "batch 271 d_loss : 0.598024\n",
      "batch 271 g_loss : 0.913282\n",
      "batch 272 d_loss : 0.576295\n",
      "batch 272 g_loss : 0.845045\n",
      "batch 273 d_loss : 0.535003\n",
      "batch 273 g_loss : 0.904901\n",
      "batch 274 d_loss : 0.524565\n",
      "batch 274 g_loss : 0.922104\n",
      "batch 275 d_loss : 0.592751\n",
      "batch 275 g_loss : 0.943915\n",
      "batch 276 d_loss : 0.594936\n",
      "batch 276 g_loss : 0.937204\n",
      "batch 277 d_loss : 0.563603\n",
      "batch 277 g_loss : 0.993300\n",
      "batch 278 d_loss : 0.555804\n",
      "batch 278 g_loss : 0.985778\n",
      "batch 279 d_loss : 0.511771\n",
      "batch 279 g_loss : 1.093553\n",
      "batch 280 d_loss : 0.540442\n",
      "batch 280 g_loss : 1.026352\n",
      "batch 281 d_loss : 0.551053\n",
      "batch 281 g_loss : 1.071058\n",
      "batch 282 d_loss : 0.582091\n",
      "batch 282 g_loss : 1.118935\n",
      "batch 283 d_loss : 0.577617\n",
      "batch 283 g_loss : 1.090393\n",
      "batch 284 d_loss : 0.528479\n",
      "batch 284 g_loss : 1.125951\n",
      "batch 285 d_loss : 0.541648\n",
      "batch 285 g_loss : 1.110184\n",
      "batch 286 d_loss : 0.579311\n",
      "batch 286 g_loss : 1.135965\n",
      "batch 287 d_loss : 0.553962\n",
      "batch 287 g_loss : 1.136718\n",
      "batch 288 d_loss : 0.497983\n",
      "batch 288 g_loss : 1.221539\n",
      "batch 289 d_loss : 0.566464\n",
      "batch 289 g_loss : 1.168363\n",
      "batch 290 d_loss : 0.638937\n",
      "batch 290 g_loss : 1.083833\n",
      "batch 291 d_loss : 0.570326\n",
      "batch 291 g_loss : 1.091989\n",
      "batch 292 d_loss : 0.546660\n",
      "batch 292 g_loss : 1.033837\n",
      "batch 293 d_loss : 0.525173\n",
      "batch 293 g_loss : 1.087029\n",
      "batch 294 d_loss : 0.529136\n",
      "batch 294 g_loss : 1.053856\n",
      "batch 295 d_loss : 0.570473\n",
      "batch 295 g_loss : 1.036685\n",
      "batch 296 d_loss : 0.526619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 296 g_loss : 1.060447\n",
      "batch 297 d_loss : 0.483550\n",
      "batch 297 g_loss : 1.064798\n",
      "batch 298 d_loss : 0.549521\n",
      "batch 298 g_loss : 1.089615\n",
      "batch 299 d_loss : 0.555634\n",
      "batch 299 g_loss : 1.092007\n",
      "batch 300 d_loss : 0.525216\n",
      "batch 300 g_loss : 1.159459\n",
      "batch 301 d_loss : 0.566051\n",
      "batch 301 g_loss : 1.063646\n",
      "batch 302 d_loss : 0.521454\n",
      "batch 302 g_loss : 1.034525\n",
      "batch 303 d_loss : 0.508925\n",
      "batch 303 g_loss : 1.084675\n",
      "batch 304 d_loss : 0.512438\n",
      "batch 304 g_loss : 1.098975\n",
      "batch 305 d_loss : 0.523531\n",
      "batch 305 g_loss : 1.126875\n",
      "batch 306 d_loss : 0.529770\n",
      "batch 306 g_loss : 1.128532\n",
      "batch 307 d_loss : 0.586404\n",
      "batch 307 g_loss : 1.102218\n",
      "batch 308 d_loss : 0.598007\n",
      "batch 308 g_loss : 1.010792\n",
      "batch 309 d_loss : 0.532905\n",
      "batch 309 g_loss : 1.073311\n",
      "batch 310 d_loss : 0.561134\n",
      "batch 310 g_loss : 0.985234\n",
      "batch 311 d_loss : 0.552264\n",
      "batch 311 g_loss : 0.957160\n",
      "batch 312 d_loss : 0.495653\n",
      "batch 312 g_loss : 1.010074\n",
      "batch 313 d_loss : 0.516226\n",
      "batch 313 g_loss : 1.091649\n",
      "batch 314 d_loss : 0.522811\n",
      "batch 314 g_loss : 1.073316\n",
      "batch 315 d_loss : 0.497247\n",
      "batch 315 g_loss : 1.072508\n",
      "batch 316 d_loss : 0.589816\n",
      "batch 316 g_loss : 1.080863\n",
      "batch 317 d_loss : 0.555773\n",
      "batch 317 g_loss : 0.985978\n",
      "batch 318 d_loss : 0.519237\n",
      "batch 318 g_loss : 1.008734\n",
      "batch 319 d_loss : 0.534952\n",
      "batch 319 g_loss : 0.953959\n",
      "batch 320 d_loss : 0.524173\n",
      "batch 320 g_loss : 1.012388\n",
      "batch 321 d_loss : 0.512372\n",
      "batch 321 g_loss : 1.009413\n",
      "batch 322 d_loss : 0.567259\n",
      "batch 322 g_loss : 0.988000\n",
      "batch 323 d_loss : 0.579752\n",
      "batch 323 g_loss : 1.037666\n",
      "batch 324 d_loss : 0.586812\n",
      "batch 324 g_loss : 0.995198\n",
      "batch 325 d_loss : 0.556578\n",
      "batch 325 g_loss : 0.891362\n",
      "batch 326 d_loss : 0.586764\n",
      "batch 326 g_loss : 0.935620\n",
      "batch 327 d_loss : 0.542589\n",
      "batch 327 g_loss : 1.025814\n",
      "batch 328 d_loss : 0.505172\n",
      "batch 328 g_loss : 1.202465\n",
      "batch 329 d_loss : 0.524259\n",
      "batch 329 g_loss : 1.241113\n",
      "batch 330 d_loss : 0.611668\n",
      "batch 330 g_loss : 1.027552\n",
      "batch 331 d_loss : 0.573153\n",
      "batch 331 g_loss : 0.961643\n",
      "batch 332 d_loss : 0.561606\n",
      "batch 332 g_loss : 0.999638\n",
      "batch 333 d_loss : 0.521997\n",
      "batch 333 g_loss : 1.064636\n",
      "batch 334 d_loss : 0.459145\n",
      "batch 334 g_loss : 1.136126\n",
      "batch 335 d_loss : 0.482415\n",
      "batch 335 g_loss : 1.131925\n",
      "batch 336 d_loss : 0.462242\n",
      "batch 336 g_loss : 1.185519\n",
      "batch 337 d_loss : 0.463600\n",
      "batch 337 g_loss : 1.158228\n",
      "batch 338 d_loss : 0.481722\n",
      "batch 338 g_loss : 1.173770\n",
      "batch 339 d_loss : 0.484902\n",
      "batch 339 g_loss : 1.148284\n",
      "batch 340 d_loss : 0.504639\n",
      "batch 340 g_loss : 1.063161\n",
      "batch 341 d_loss : 0.430527\n",
      "batch 341 g_loss : 1.097641\n",
      "batch 342 d_loss : 0.479380\n",
      "batch 342 g_loss : 1.112947\n",
      "batch 343 d_loss : 0.494983\n",
      "batch 343 g_loss : 1.145761\n",
      "batch 344 d_loss : 0.543120\n",
      "batch 344 g_loss : 1.090670\n",
      "batch 345 d_loss : 0.528917\n",
      "batch 345 g_loss : 1.100978\n",
      "batch 346 d_loss : 0.509769\n",
      "batch 346 g_loss : 1.102143\n",
      "batch 347 d_loss : 0.511616\n",
      "batch 347 g_loss : 1.158685\n",
      "batch 348 d_loss : 0.481982\n",
      "batch 348 g_loss : 1.211643\n",
      "batch 349 d_loss : 0.491529\n",
      "batch 349 g_loss : 1.159752\n",
      "batch 350 d_loss : 0.510207\n",
      "batch 350 g_loss : 1.101494\n",
      "batch 351 d_loss : 0.478934\n",
      "batch 351 g_loss : 1.196448\n",
      "batch 352 d_loss : 0.498491\n",
      "batch 352 g_loss : 1.196564\n",
      "batch 353 d_loss : 0.506327\n",
      "batch 353 g_loss : 1.131668\n",
      "batch 354 d_loss : 0.490450\n",
      "batch 354 g_loss : 1.088986\n",
      "batch 355 d_loss : 0.514956\n",
      "batch 355 g_loss : 1.121312\n",
      "batch 356 d_loss : 0.460993\n",
      "batch 356 g_loss : 1.215893\n",
      "batch 357 d_loss : 0.491136\n",
      "batch 357 g_loss : 1.182360\n",
      "batch 358 d_loss : 0.473664\n",
      "batch 358 g_loss : 1.176782\n",
      "batch 359 d_loss : 0.517401\n",
      "batch 359 g_loss : 1.051804\n",
      "batch 360 d_loss : 0.490942\n",
      "batch 360 g_loss : 1.141399\n",
      "batch 361 d_loss : 0.452371\n",
      "batch 361 g_loss : 1.267249\n",
      "batch 362 d_loss : 0.514675\n",
      "batch 362 g_loss : 1.224085\n",
      "batch 363 d_loss : 0.478460\n",
      "batch 363 g_loss : 1.253076\n",
      "batch 364 d_loss : 0.482493\n",
      "batch 364 g_loss : 1.269009\n",
      "batch 365 d_loss : 0.432059\n",
      "batch 365 g_loss : 1.238710\n",
      "batch 366 d_loss : 0.456578\n",
      "batch 366 g_loss : 1.172949\n",
      "batch 367 d_loss : 0.516507\n",
      "batch 367 g_loss : 1.125793\n",
      "batch 368 d_loss : 0.474299\n",
      "batch 368 g_loss : 1.151727\n",
      "batch 369 d_loss : 0.434235\n",
      "batch 369 g_loss : 1.162053\n",
      "batch 370 d_loss : 0.504120\n",
      "batch 370 g_loss : 1.179452\n",
      "batch 371 d_loss : 0.514164\n",
      "batch 371 g_loss : 1.116247\n",
      "batch 372 d_loss : 0.463880\n",
      "batch 372 g_loss : 1.180995\n",
      "batch 373 d_loss : 0.472324\n",
      "batch 373 g_loss : 1.246121\n",
      "batch 374 d_loss : 0.470923\n",
      "batch 374 g_loss : 1.198670\n",
      "batch 375 d_loss : 0.447553\n",
      "batch 375 g_loss : 1.216774\n",
      "batch 376 d_loss : 0.448359\n",
      "batch 376 g_loss : 1.233343\n",
      "batch 377 d_loss : 0.494503\n",
      "batch 377 g_loss : 1.134592\n",
      "batch 378 d_loss : 0.470825\n",
      "batch 378 g_loss : 1.094466\n",
      "batch 379 d_loss : 0.454667\n",
      "batch 379 g_loss : 1.128690\n",
      "batch 380 d_loss : 0.452833\n",
      "batch 380 g_loss : 1.222965\n",
      "batch 381 d_loss : 0.437385\n",
      "batch 381 g_loss : 1.235327\n",
      "batch 382 d_loss : 0.472196\n",
      "batch 382 g_loss : 1.197646\n",
      "batch 383 d_loss : 0.566410\n",
      "batch 383 g_loss : 0.986236\n",
      "batch 384 d_loss : 0.491592\n",
      "batch 384 g_loss : 1.079526\n",
      "batch 385 d_loss : 0.458430\n",
      "batch 385 g_loss : 1.179261\n",
      "batch 386 d_loss : 0.534448\n",
      "batch 386 g_loss : 1.163553\n",
      "batch 387 d_loss : 0.518139\n",
      "batch 387 g_loss : 1.155371\n",
      "batch 388 d_loss : 0.423254\n",
      "batch 388 g_loss : 1.223336\n",
      "batch 389 d_loss : 0.517870\n",
      "batch 389 g_loss : 1.133278\n",
      "batch 390 d_loss : 0.477546\n",
      "batch 390 g_loss : 0.938354\n",
      "batch 391 d_loss : 0.421570\n",
      "batch 391 g_loss : 1.125099\n",
      "batch 392 d_loss : 0.424693\n",
      "batch 392 g_loss : 1.329619\n",
      "batch 393 d_loss : 0.489201\n",
      "batch 393 g_loss : 1.155661\n",
      "batch 394 d_loss : 0.499090\n",
      "batch 394 g_loss : 1.085725\n",
      "batch 395 d_loss : 0.457718\n",
      "batch 395 g_loss : 1.120339\n",
      "batch 396 d_loss : 0.425775\n",
      "batch 396 g_loss : 1.257426\n",
      "batch 397 d_loss : 0.416389\n",
      "batch 397 g_loss : 1.281584\n",
      "batch 398 d_loss : 0.390684\n",
      "batch 398 g_loss : 1.254433\n",
      "batch 399 d_loss : 0.458868\n",
      "batch 399 g_loss : 1.321015\n",
      "batch 400 d_loss : 0.479661\n",
      "batch 400 g_loss : 1.097868\n",
      "batch 401 d_loss : 0.448977\n",
      "batch 401 g_loss : 1.120011\n",
      "batch 402 d_loss : 0.450936\n",
      "batch 402 g_loss : 1.159411\n",
      "batch 403 d_loss : 0.460659\n",
      "batch 403 g_loss : 1.180087\n",
      "batch 404 d_loss : 0.487067\n",
      "batch 404 g_loss : 1.127439\n",
      "batch 405 d_loss : 0.416529\n",
      "batch 405 g_loss : 1.233148\n",
      "batch 406 d_loss : 0.494652\n",
      "batch 406 g_loss : 1.174361\n",
      "batch 407 d_loss : 0.543356\n",
      "batch 407 g_loss : 1.039578\n",
      "batch 408 d_loss : 0.426805\n",
      "batch 408 g_loss : 1.195538\n",
      "batch 409 d_loss : 0.423622\n",
      "batch 409 g_loss : 1.366462\n",
      "batch 410 d_loss : 0.408633\n",
      "batch 410 g_loss : 1.382534\n",
      "batch 411 d_loss : 0.472267\n",
      "batch 411 g_loss : 1.252859\n",
      "batch 412 d_loss : 0.446998\n",
      "batch 412 g_loss : 1.229981\n",
      "batch 413 d_loss : 0.428225\n",
      "batch 413 g_loss : 1.280231\n",
      "batch 414 d_loss : 0.438517\n",
      "batch 414 g_loss : 1.283386\n",
      "batch 415 d_loss : 0.431324\n",
      "batch 415 g_loss : 1.249107\n",
      "batch 416 d_loss : 0.438594\n",
      "batch 416 g_loss : 1.162184\n",
      "batch 417 d_loss : 0.458009\n",
      "batch 417 g_loss : 1.214776\n",
      "batch 418 d_loss : 0.444545\n",
      "batch 418 g_loss : 1.177815\n",
      "batch 419 d_loss : 0.422973\n",
      "batch 419 g_loss : 1.352443\n",
      "batch 420 d_loss : 0.402742\n",
      "batch 420 g_loss : 1.412635\n",
      "batch 421 d_loss : 0.469617\n",
      "batch 421 g_loss : 1.234651\n",
      "batch 422 d_loss : 0.459525\n",
      "batch 422 g_loss : 1.216534\n",
      "batch 423 d_loss : 0.414294\n",
      "batch 423 g_loss : 1.280901\n",
      "batch 424 d_loss : 0.432380\n",
      "batch 424 g_loss : 1.281094\n",
      "batch 425 d_loss : 0.459476\n",
      "batch 425 g_loss : 1.200500\n",
      "batch 426 d_loss : 0.424873\n",
      "batch 426 g_loss : 1.313177\n",
      "batch 427 d_loss : 0.411786\n",
      "batch 427 g_loss : 1.306898\n",
      "batch 428 d_loss : 0.491727\n",
      "batch 428 g_loss : 1.128082\n",
      "batch 429 d_loss : 0.521336\n",
      "batch 429 g_loss : 1.096074\n",
      "batch 430 d_loss : 0.457992\n",
      "batch 430 g_loss : 1.224100\n",
      "batch 431 d_loss : 0.457383\n",
      "batch 431 g_loss : 1.331848\n",
      "batch 432 d_loss : 0.418268\n",
      "batch 432 g_loss : 1.298822\n",
      "batch 433 d_loss : 0.430695\n",
      "batch 433 g_loss : 1.239829\n",
      "batch 434 d_loss : 0.498814\n",
      "batch 434 g_loss : 1.211587\n",
      "batch 435 d_loss : 0.432175\n",
      "batch 435 g_loss : 1.250107\n",
      "batch 436 d_loss : 0.397096\n",
      "batch 436 g_loss : 1.331514\n",
      "batch 437 d_loss : 0.431450\n",
      "batch 437 g_loss : 1.275064\n",
      "batch 438 d_loss : 0.453522\n",
      "batch 438 g_loss : 1.103249\n",
      "batch 439 d_loss : 0.479724\n",
      "batch 439 g_loss : 1.185801\n",
      "batch 440 d_loss : 0.440939\n",
      "batch 440 g_loss : 1.242764\n",
      "batch 441 d_loss : 0.530558\n",
      "batch 441 g_loss : 1.032382\n",
      "batch 442 d_loss : 0.506683\n",
      "batch 442 g_loss : 1.097542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 443 d_loss : 0.466241\n",
      "batch 443 g_loss : 1.235449\n",
      "batch 444 d_loss : 0.432919\n",
      "batch 444 g_loss : 1.237295\n",
      "batch 445 d_loss : 0.467291\n",
      "batch 445 g_loss : 1.117564\n",
      "batch 446 d_loss : 0.454384\n",
      "batch 446 g_loss : 1.133072\n",
      "batch 447 d_loss : 0.442760\n",
      "batch 447 g_loss : 1.202503\n",
      "batch 448 d_loss : 0.446953\n",
      "batch 448 g_loss : 1.182075\n",
      "batch 449 d_loss : 0.440620\n",
      "batch 449 g_loss : 1.158328\n",
      "batch 450 d_loss : 0.427054\n",
      "batch 450 g_loss : 1.304453\n",
      "batch 451 d_loss : 0.390578\n",
      "batch 451 g_loss : 1.255840\n",
      "batch 452 d_loss : 0.463106\n",
      "batch 452 g_loss : 1.161743\n",
      "batch 453 d_loss : 0.440882\n",
      "batch 453 g_loss : 1.329164\n",
      "batch 454 d_loss : 0.384138\n",
      "batch 454 g_loss : 1.230767\n",
      "batch 455 d_loss : 0.446092\n",
      "batch 455 g_loss : 1.262440\n",
      "batch 456 d_loss : 0.494039\n",
      "batch 456 g_loss : 1.256007\n",
      "batch 457 d_loss : 0.429485\n",
      "batch 457 g_loss : 1.261782\n",
      "batch 458 d_loss : 0.329171\n",
      "batch 458 g_loss : 1.358471\n",
      "batch 459 d_loss : 0.429144\n",
      "batch 459 g_loss : 1.215102\n",
      "batch 460 d_loss : 0.414207\n",
      "batch 460 g_loss : 1.271630\n",
      "batch 461 d_loss : 0.342295\n",
      "batch 461 g_loss : 1.459188\n",
      "batch 462 d_loss : 0.396444\n",
      "batch 462 g_loss : 1.353492\n",
      "batch 463 d_loss : 0.470839\n",
      "batch 463 g_loss : 1.398256\n",
      "batch 464 d_loss : 0.549156\n",
      "batch 464 g_loss : 1.288140\n",
      "batch 465 d_loss : 0.373226\n",
      "batch 465 g_loss : 1.398346\n",
      "batch 466 d_loss : 0.424400\n",
      "batch 466 g_loss : 1.230884\n",
      "batch 467 d_loss : 0.435158\n",
      "batch 467 g_loss : 1.239219\n",
      "Epoch is 1\n",
      "Number of batches 468\n",
      "batch 0 d_loss : 0.452422\n",
      "batch 0 g_loss : 1.237074\n",
      "batch 1 d_loss : 0.450532\n",
      "batch 1 g_loss : 1.229313\n",
      "batch 2 d_loss : 0.408442\n",
      "batch 2 g_loss : 1.110162\n",
      "batch 3 d_loss : 0.463812\n",
      "batch 3 g_loss : 1.156406\n",
      "batch 4 d_loss : 0.441597\n",
      "batch 4 g_loss : 1.103717\n",
      "batch 5 d_loss : 0.464714\n",
      "batch 5 g_loss : 1.225400\n",
      "batch 6 d_loss : 0.444035\n",
      "batch 6 g_loss : 1.235156\n",
      "batch 7 d_loss : 0.445448\n",
      "batch 7 g_loss : 1.226949\n",
      "batch 8 d_loss : 0.462960\n",
      "batch 8 g_loss : 1.262635\n",
      "batch 9 d_loss : 0.486839\n",
      "batch 9 g_loss : 1.164086\n",
      "batch 10 d_loss : 0.475463\n",
      "batch 10 g_loss : 1.249658\n",
      "batch 11 d_loss : 0.463925\n",
      "batch 11 g_loss : 1.186531\n",
      "batch 12 d_loss : 0.435839\n",
      "batch 12 g_loss : 1.274741\n",
      "batch 13 d_loss : 0.386746\n",
      "batch 13 g_loss : 1.424688\n",
      "batch 14 d_loss : 0.470897\n",
      "batch 14 g_loss : 1.163157\n",
      "batch 15 d_loss : 0.482269\n",
      "batch 15 g_loss : 1.204491\n",
      "batch 16 d_loss : 0.411334\n",
      "batch 16 g_loss : 1.392178\n",
      "batch 17 d_loss : 0.419900\n",
      "batch 17 g_loss : 1.345963\n",
      "batch 18 d_loss : 0.416542\n",
      "batch 18 g_loss : 1.205828\n",
      "batch 19 d_loss : 0.413489\n",
      "batch 19 g_loss : 1.288810\n",
      "batch 20 d_loss : 0.401821\n",
      "batch 20 g_loss : 1.450896\n",
      "batch 21 d_loss : 0.510755\n",
      "batch 21 g_loss : 1.097682\n",
      "batch 22 d_loss : 0.458084\n",
      "batch 22 g_loss : 1.070998\n",
      "batch 23 d_loss : 0.399380\n",
      "batch 23 g_loss : 1.458663\n",
      "batch 24 d_loss : 0.341594\n",
      "batch 24 g_loss : 1.519722\n",
      "batch 25 d_loss : 0.379041\n",
      "batch 25 g_loss : 1.324038\n",
      "batch 26 d_loss : 0.408754\n",
      "batch 26 g_loss : 1.273962\n",
      "batch 27 d_loss : 0.407247\n",
      "batch 27 g_loss : 1.275126\n",
      "batch 28 d_loss : 0.446544\n",
      "batch 28 g_loss : 1.211494\n",
      "batch 29 d_loss : 0.402463\n",
      "batch 29 g_loss : 1.324852\n",
      "batch 30 d_loss : 0.363742\n",
      "batch 30 g_loss : 1.550641\n",
      "batch 31 d_loss : 0.415086\n",
      "batch 31 g_loss : 1.350001\n",
      "batch 32 d_loss : 0.424092\n",
      "batch 32 g_loss : 1.203015\n",
      "batch 33 d_loss : 0.392574\n",
      "batch 33 g_loss : 1.423350\n",
      "batch 34 d_loss : 0.408483\n",
      "batch 34 g_loss : 1.406062\n",
      "batch 35 d_loss : 0.417482\n",
      "batch 35 g_loss : 1.180830\n",
      "batch 36 d_loss : 0.484736\n",
      "batch 36 g_loss : 1.236677\n",
      "batch 37 d_loss : 0.468999\n",
      "batch 37 g_loss : 1.031659\n",
      "batch 38 d_loss : 0.437841\n",
      "batch 38 g_loss : 1.471873\n",
      "batch 39 d_loss : 0.393421\n",
      "batch 39 g_loss : 1.427260\n",
      "batch 40 d_loss : 0.379119\n",
      "batch 40 g_loss : 1.434932\n",
      "batch 41 d_loss : 0.420569\n",
      "batch 41 g_loss : 1.335591\n",
      "batch 42 d_loss : 0.408218\n",
      "batch 42 g_loss : 1.268290\n",
      "batch 43 d_loss : 0.355029\n",
      "batch 43 g_loss : 1.450918\n",
      "batch 44 d_loss : 0.379286\n",
      "batch 44 g_loss : 1.282931\n",
      "batch 45 d_loss : 0.364554\n",
      "batch 45 g_loss : 1.247310\n",
      "batch 46 d_loss : 0.421653\n",
      "batch 46 g_loss : 1.413478\n",
      "batch 47 d_loss : 0.457753\n",
      "batch 47 g_loss : 1.344256\n",
      "batch 48 d_loss : 0.408565\n",
      "batch 48 g_loss : 1.406731\n",
      "batch 49 d_loss : 0.367028\n",
      "batch 49 g_loss : 1.289336\n",
      "batch 50 d_loss : 0.395451\n",
      "batch 50 g_loss : 1.297844\n",
      "batch 51 d_loss : 0.313308\n",
      "batch 51 g_loss : 1.511210\n",
      "batch 52 d_loss : 0.401125\n",
      "batch 52 g_loss : 1.180166\n",
      "batch 53 d_loss : 0.413179\n",
      "batch 53 g_loss : 1.159024\n",
      "batch 54 d_loss : 0.394812\n",
      "batch 54 g_loss : 1.384561\n",
      "batch 55 d_loss : 0.380809\n",
      "batch 55 g_loss : 1.413471\n",
      "batch 56 d_loss : 0.427700\n",
      "batch 56 g_loss : 1.093633\n",
      "batch 57 d_loss : 0.399212\n",
      "batch 57 g_loss : 1.173867\n",
      "batch 58 d_loss : 0.332846\n",
      "batch 58 g_loss : 1.558139\n",
      "batch 59 d_loss : 0.398276\n",
      "batch 59 g_loss : 1.364759\n",
      "batch 60 d_loss : 0.380584\n",
      "batch 60 g_loss : 1.407286\n",
      "batch 61 d_loss : 0.485223\n",
      "batch 61 g_loss : 1.389513\n",
      "batch 62 d_loss : 0.457709\n",
      "batch 62 g_loss : 1.164806\n",
      "batch 63 d_loss : 0.371976\n",
      "batch 63 g_loss : 1.513785\n",
      "batch 64 d_loss : 0.365434\n",
      "batch 64 g_loss : 1.410099\n",
      "batch 65 d_loss : 0.431565\n",
      "batch 65 g_loss : 1.259368\n",
      "batch 66 d_loss : 0.499626\n",
      "batch 66 g_loss : 1.496370\n",
      "batch 67 d_loss : 0.430877\n",
      "batch 67 g_loss : 1.403115\n",
      "batch 68 d_loss : 0.374821\n",
      "batch 68 g_loss : 1.468242\n",
      "batch 69 d_loss : 0.405718\n",
      "batch 69 g_loss : 1.379415\n",
      "batch 70 d_loss : 0.366035\n",
      "batch 70 g_loss : 1.604807\n",
      "batch 71 d_loss : 0.357656\n",
      "batch 71 g_loss : 1.211875\n",
      "batch 72 d_loss : 0.375912\n",
      "batch 72 g_loss : 1.313910\n",
      "batch 73 d_loss : 0.376928\n",
      "batch 73 g_loss : 1.443376\n",
      "batch 74 d_loss : 0.408230\n",
      "batch 74 g_loss : 1.250248\n",
      "batch 75 d_loss : 0.403439\n",
      "batch 75 g_loss : 1.333678\n",
      "batch 76 d_loss : 0.323065\n",
      "batch 76 g_loss : 1.757009\n",
      "batch 77 d_loss : 0.367720\n",
      "batch 77 g_loss : 1.388306\n",
      "batch 78 d_loss : 0.357005\n",
      "batch 78 g_loss : 1.437357\n",
      "batch 79 d_loss : 0.371839\n",
      "batch 79 g_loss : 1.437989\n",
      "batch 80 d_loss : 0.396699\n",
      "batch 80 g_loss : 1.589411\n",
      "batch 81 d_loss : 0.306883\n",
      "batch 81 g_loss : 1.540333\n",
      "batch 82 d_loss : 0.341209\n",
      "batch 82 g_loss : 1.359920\n",
      "batch 83 d_loss : 0.367877\n",
      "batch 83 g_loss : 1.242911\n",
      "batch 84 d_loss : 0.360158\n",
      "batch 84 g_loss : 1.639784\n",
      "batch 85 d_loss : 0.371302\n",
      "batch 85 g_loss : 1.463503\n",
      "batch 86 d_loss : 0.353596\n",
      "batch 86 g_loss : 1.450039\n",
      "batch 87 d_loss : 0.332092\n",
      "batch 87 g_loss : 1.681867\n",
      "batch 88 d_loss : 0.381108\n",
      "batch 88 g_loss : 1.425814\n",
      "batch 89 d_loss : 0.349848\n",
      "batch 89 g_loss : 1.548443\n",
      "batch 90 d_loss : 0.406913\n",
      "batch 90 g_loss : 1.168299\n",
      "batch 91 d_loss : 0.379948\n",
      "batch 91 g_loss : 1.622293\n",
      "batch 92 d_loss : 0.312493\n",
      "batch 92 g_loss : 1.632102\n",
      "batch 93 d_loss : 0.347458\n",
      "batch 93 g_loss : 1.370370\n",
      "batch 94 d_loss : 0.339093\n",
      "batch 94 g_loss : 1.458213\n",
      "batch 95 d_loss : 0.388971\n",
      "batch 95 g_loss : 1.668444\n",
      "batch 96 d_loss : 0.430533\n",
      "batch 96 g_loss : 1.079428\n",
      "batch 97 d_loss : 0.357391\n",
      "batch 97 g_loss : 1.586950\n",
      "batch 98 d_loss : 0.341335\n",
      "batch 98 g_loss : 1.692762\n",
      "batch 99 d_loss : 0.363074\n",
      "batch 99 g_loss : 1.325213\n",
      "batch 100 d_loss : 0.362001\n",
      "batch 100 g_loss : 1.430586\n",
      "batch 101 d_loss : 0.435223\n",
      "batch 101 g_loss : 1.394426\n",
      "batch 102 d_loss : 0.394419\n",
      "batch 102 g_loss : 1.585038\n",
      "batch 103 d_loss : 0.384052\n",
      "batch 103 g_loss : 1.319226\n",
      "batch 104 d_loss : 0.346935\n",
      "batch 104 g_loss : 1.540652\n",
      "batch 105 d_loss : 0.320583\n",
      "batch 105 g_loss : 1.788566\n",
      "batch 106 d_loss : 0.423567\n",
      "batch 106 g_loss : 0.899955\n",
      "batch 107 d_loss : 0.428324\n",
      "batch 107 g_loss : 1.967638\n",
      "batch 108 d_loss : 0.417270\n",
      "batch 108 g_loss : 1.086796\n",
      "batch 109 d_loss : 0.428332\n",
      "batch 109 g_loss : 1.320674\n",
      "batch 110 d_loss : 0.452168\n",
      "batch 110 g_loss : 1.308367\n",
      "batch 111 d_loss : 0.398196\n",
      "batch 111 g_loss : 1.382190\n",
      "batch 112 d_loss : 0.373296\n",
      "batch 112 g_loss : 1.663499\n",
      "batch 113 d_loss : 0.392694\n",
      "batch 113 g_loss : 1.159706\n",
      "batch 114 d_loss : 0.436587\n",
      "batch 114 g_loss : 1.572580\n",
      "batch 115 d_loss : 0.490614\n",
      "batch 115 g_loss : 0.773440\n",
      "batch 116 d_loss : 0.474696\n",
      "batch 116 g_loss : 2.514725\n",
      "batch 117 d_loss : 0.444566\n",
      "batch 117 g_loss : 1.011863\n",
      "batch 118 d_loss : 0.365788\n",
      "batch 118 g_loss : 1.604815\n",
      "batch 119 d_loss : 0.296048\n",
      "batch 119 g_loss : 1.458921\n",
      "batch 120 d_loss : 0.359975\n",
      "batch 120 g_loss : 1.212062\n",
      "batch 121 d_loss : 0.362024\n",
      "batch 121 g_loss : 1.524229\n",
      "batch 122 d_loss : 0.314989\n",
      "batch 122 g_loss : 1.622283\n",
      "batch 123 d_loss : 0.348556\n",
      "batch 123 g_loss : 1.239103\n",
      "batch 124 d_loss : 0.412869\n",
      "batch 124 g_loss : 1.768499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 125 d_loss : 0.386293\n",
      "batch 125 g_loss : 1.228069\n",
      "batch 126 d_loss : 0.348796\n",
      "batch 126 g_loss : 1.888906\n",
      "batch 127 d_loss : 0.354609\n",
      "batch 127 g_loss : 1.376099\n",
      "batch 128 d_loss : 0.294960\n",
      "batch 128 g_loss : 1.840254\n",
      "batch 129 d_loss : 0.299020\n",
      "batch 129 g_loss : 1.371385\n",
      "batch 130 d_loss : 0.319235\n",
      "batch 130 g_loss : 1.799068\n",
      "batch 131 d_loss : 0.376376\n",
      "batch 131 g_loss : 0.890320\n",
      "batch 132 d_loss : 0.398667\n",
      "batch 132 g_loss : 2.203684\n",
      "batch 133 d_loss : 0.413587\n",
      "batch 133 g_loss : 0.852041\n",
      "batch 134 d_loss : 0.401793\n",
      "batch 134 g_loss : 2.286932\n",
      "batch 135 d_loss : 0.392231\n",
      "batch 135 g_loss : 0.995199\n",
      "batch 136 d_loss : 0.398062\n",
      "batch 136 g_loss : 2.182449\n",
      "batch 137 d_loss : 0.568440\n",
      "batch 137 g_loss : 0.301770\n",
      "batch 138 d_loss : 0.813412\n",
      "batch 138 g_loss : 3.461815\n",
      "batch 139 d_loss : 0.778626\n",
      "batch 139 g_loss : 0.420164\n",
      "batch 140 d_loss : 0.647006\n",
      "batch 140 g_loss : 3.328544\n",
      "batch 141 d_loss : 0.601103\n",
      "batch 141 g_loss : 0.734650\n",
      "batch 142 d_loss : 0.485911\n",
      "batch 142 g_loss : 2.492842\n",
      "batch 143 d_loss : 0.459679\n",
      "batch 143 g_loss : 0.774115\n",
      "batch 144 d_loss : 0.436874\n",
      "batch 144 g_loss : 2.199293\n",
      "batch 145 d_loss : 0.367287\n",
      "batch 145 g_loss : 1.056986\n",
      "batch 146 d_loss : 0.333183\n",
      "batch 146 g_loss : 1.997050\n",
      "batch 147 d_loss : 0.358630\n",
      "batch 147 g_loss : 1.036101\n",
      "batch 148 d_loss : 0.361132\n",
      "batch 148 g_loss : 2.083893\n",
      "batch 149 d_loss : 0.361434\n",
      "batch 149 g_loss : 0.954252\n",
      "batch 150 d_loss : 0.418755\n",
      "batch 150 g_loss : 1.978328\n",
      "batch 151 d_loss : 0.423719\n",
      "batch 151 g_loss : 1.249437\n",
      "batch 152 d_loss : 0.433698\n",
      "batch 152 g_loss : 1.479208\n",
      "batch 153 d_loss : 0.360516\n",
      "batch 153 g_loss : 1.597532\n",
      "batch 154 d_loss : 0.317526\n",
      "batch 154 g_loss : 1.681969\n",
      "batch 155 d_loss : 0.376940\n",
      "batch 155 g_loss : 1.119025\n",
      "batch 156 d_loss : 0.377236\n",
      "batch 156 g_loss : 1.724660\n",
      "batch 157 d_loss : 0.360370\n",
      "batch 157 g_loss : 1.250888\n",
      "batch 158 d_loss : 0.413622\n",
      "batch 158 g_loss : 1.759759\n",
      "batch 159 d_loss : 0.338181\n",
      "batch 159 g_loss : 1.505578\n",
      "batch 160 d_loss : 0.344553\n",
      "batch 160 g_loss : 1.984179\n",
      "batch 161 d_loss : 0.376947\n",
      "batch 161 g_loss : 1.291377\n",
      "batch 162 d_loss : 0.329134\n",
      "batch 162 g_loss : 1.656063\n",
      "batch 163 d_loss : 0.386984\n",
      "batch 163 g_loss : 1.131470\n",
      "batch 164 d_loss : 0.369313\n",
      "batch 164 g_loss : 1.834318\n",
      "batch 165 d_loss : 0.325572\n",
      "batch 165 g_loss : 1.289105\n",
      "batch 166 d_loss : 0.343628\n",
      "batch 166 g_loss : 1.514477\n",
      "batch 167 d_loss : 0.374220\n",
      "batch 167 g_loss : 1.550257\n",
      "batch 168 d_loss : 0.307659\n",
      "batch 168 g_loss : 1.634201\n",
      "batch 169 d_loss : 0.310413\n",
      "batch 169 g_loss : 1.370649\n",
      "batch 170 d_loss : 0.377777\n",
      "batch 170 g_loss : 1.650507\n",
      "batch 171 d_loss : 0.405170\n",
      "batch 171 g_loss : 1.282406\n",
      "batch 172 d_loss : 0.366586\n",
      "batch 172 g_loss : 1.749093\n",
      "batch 173 d_loss : 0.337444\n",
      "batch 173 g_loss : 1.194391\n",
      "batch 174 d_loss : 0.320002\n",
      "batch 174 g_loss : 2.165241\n",
      "batch 175 d_loss : 0.424248\n",
      "batch 175 g_loss : 0.706086\n",
      "batch 176 d_loss : 0.506627\n",
      "batch 176 g_loss : 2.111592\n",
      "batch 177 d_loss : 0.519619\n",
      "batch 177 g_loss : 0.953506\n",
      "batch 178 d_loss : 0.431734\n",
      "batch 178 g_loss : 1.922567\n",
      "batch 179 d_loss : 0.423776\n",
      "batch 179 g_loss : 0.997602\n",
      "batch 180 d_loss : 0.438284\n",
      "batch 180 g_loss : 2.218843\n",
      "batch 181 d_loss : 0.415851\n",
      "batch 181 g_loss : 0.963115\n",
      "batch 182 d_loss : 0.430010\n",
      "batch 182 g_loss : 2.277309\n",
      "batch 183 d_loss : 0.404889\n",
      "batch 183 g_loss : 0.938538\n",
      "batch 184 d_loss : 0.414470\n",
      "batch 184 g_loss : 2.200047\n",
      "batch 185 d_loss : 0.399737\n",
      "batch 185 g_loss : 0.752989\n",
      "batch 186 d_loss : 0.445152\n",
      "batch 186 g_loss : 2.389667\n",
      "batch 187 d_loss : 0.412841\n",
      "batch 187 g_loss : 1.080853\n",
      "batch 188 d_loss : 0.396690\n",
      "batch 188 g_loss : 2.127564\n",
      "batch 189 d_loss : 0.419919\n",
      "batch 189 g_loss : 0.885858\n",
      "batch 190 d_loss : 0.434796\n",
      "batch 190 g_loss : 2.419796\n",
      "batch 191 d_loss : 0.505669\n",
      "batch 191 g_loss : 0.611415\n",
      "batch 192 d_loss : 0.536352\n",
      "batch 192 g_loss : 2.840308\n",
      "batch 193 d_loss : 0.472817\n",
      "batch 193 g_loss : 1.008987\n",
      "batch 194 d_loss : 0.374866\n",
      "batch 194 g_loss : 1.918256\n",
      "batch 195 d_loss : 0.344826\n",
      "batch 195 g_loss : 1.050146\n",
      "batch 196 d_loss : 0.347961\n",
      "batch 196 g_loss : 2.235239\n",
      "batch 197 d_loss : 0.423239\n",
      "batch 197 g_loss : 1.209365\n",
      "batch 198 d_loss : 0.407952\n",
      "batch 198 g_loss : 2.063827\n",
      "batch 199 d_loss : 0.387524\n",
      "batch 199 g_loss : 1.098053\n",
      "batch 200 d_loss : 0.376711\n",
      "batch 200 g_loss : 2.141690\n",
      "batch 201 d_loss : 0.375630\n",
      "batch 201 g_loss : 0.794401\n",
      "batch 202 d_loss : 0.466633\n",
      "batch 202 g_loss : 2.745111\n",
      "batch 203 d_loss : 0.541062\n",
      "batch 203 g_loss : 0.675577\n",
      "batch 204 d_loss : 0.511940\n",
      "batch 204 g_loss : 2.635994\n",
      "batch 205 d_loss : 0.476838\n",
      "batch 205 g_loss : 0.728468\n",
      "batch 206 d_loss : 0.515476\n",
      "batch 206 g_loss : 2.766135\n",
      "batch 207 d_loss : 0.738620\n",
      "batch 207 g_loss : 0.215684\n",
      "batch 208 d_loss : 1.143952\n",
      "batch 208 g_loss : 3.506819\n",
      "batch 209 d_loss : 0.761558\n",
      "batch 209 g_loss : 0.791435\n",
      "batch 210 d_loss : 0.453151\n",
      "batch 210 g_loss : 2.716602\n",
      "batch 211 d_loss : 0.529191\n",
      "batch 211 g_loss : 0.675594\n",
      "batch 212 d_loss : 0.516803\n",
      "batch 212 g_loss : 2.288981\n",
      "batch 213 d_loss : 0.540296\n",
      "batch 213 g_loss : 0.558377\n",
      "batch 214 d_loss : 0.572500\n",
      "batch 214 g_loss : 2.340984\n",
      "batch 215 d_loss : 0.482034\n",
      "batch 215 g_loss : 0.986864\n",
      "batch 216 d_loss : 0.411585\n",
      "batch 216 g_loss : 1.875251\n",
      "batch 217 d_loss : 0.448729\n",
      "batch 217 g_loss : 0.715394\n",
      "batch 218 d_loss : 0.501933\n",
      "batch 218 g_loss : 2.311911\n",
      "batch 219 d_loss : 0.495387\n",
      "batch 219 g_loss : 1.117022\n",
      "batch 220 d_loss : 0.426358\n",
      "batch 220 g_loss : 1.641375\n",
      "batch 221 d_loss : 0.462357\n",
      "batch 221 g_loss : 1.157702\n",
      "batch 222 d_loss : 0.442762\n",
      "batch 222 g_loss : 1.486173\n",
      "batch 223 d_loss : 0.449434\n",
      "batch 223 g_loss : 1.102189\n",
      "batch 224 d_loss : 0.369939\n",
      "batch 224 g_loss : 1.905222\n",
      "batch 225 d_loss : 0.469519\n",
      "batch 225 g_loss : 1.089475\n",
      "batch 226 d_loss : 0.445008\n",
      "batch 226 g_loss : 1.627472\n",
      "batch 227 d_loss : 0.456916\n",
      "batch 227 g_loss : 0.783250\n",
      "batch 228 d_loss : 0.490403\n",
      "batch 228 g_loss : 1.835010\n",
      "batch 229 d_loss : 0.455632\n",
      "batch 229 g_loss : 1.323029\n",
      "batch 230 d_loss : 0.391314\n",
      "batch 230 g_loss : 1.462896\n",
      "batch 231 d_loss : 0.366109\n",
      "batch 231 g_loss : 1.210122\n",
      "batch 232 d_loss : 0.410598\n",
      "batch 232 g_loss : 1.586522\n",
      "batch 233 d_loss : 0.445305\n",
      "batch 233 g_loss : 0.984909\n",
      "batch 234 d_loss : 0.436920\n",
      "batch 234 g_loss : 1.606230\n",
      "batch 235 d_loss : 0.496610\n",
      "batch 235 g_loss : 0.868435\n",
      "batch 236 d_loss : 0.450477\n",
      "batch 236 g_loss : 2.118030\n",
      "batch 237 d_loss : 0.487802\n",
      "batch 237 g_loss : 0.830081\n",
      "batch 238 d_loss : 0.458531\n",
      "batch 238 g_loss : 2.124903\n",
      "batch 239 d_loss : 0.549149\n",
      "batch 239 g_loss : 0.464973\n",
      "batch 240 d_loss : 0.663921\n",
      "batch 240 g_loss : 2.434776\n",
      "batch 241 d_loss : 0.528273\n",
      "batch 241 g_loss : 0.915610\n",
      "batch 242 d_loss : 0.425220\n",
      "batch 242 g_loss : 1.971545\n",
      "batch 243 d_loss : 0.465228\n",
      "batch 243 g_loss : 0.828572\n",
      "batch 244 d_loss : 0.430630\n",
      "batch 244 g_loss : 1.974129\n",
      "batch 245 d_loss : 0.458090\n",
      "batch 245 g_loss : 0.899894\n",
      "batch 246 d_loss : 0.459522\n",
      "batch 246 g_loss : 2.304512\n",
      "batch 247 d_loss : 0.572793\n",
      "batch 247 g_loss : 0.475773\n",
      "batch 248 d_loss : 0.653512\n",
      "batch 248 g_loss : 2.398160\n",
      "batch 249 d_loss : 0.582551\n",
      "batch 249 g_loss : 0.700905\n",
      "batch 250 d_loss : 0.550198\n",
      "batch 250 g_loss : 1.979784\n",
      "batch 251 d_loss : 0.528514\n",
      "batch 251 g_loss : 0.711119\n",
      "batch 252 d_loss : 0.621084\n",
      "batch 252 g_loss : 1.474225\n",
      "batch 253 d_loss : 0.642039\n",
      "batch 253 g_loss : 1.044226\n",
      "batch 254 d_loss : 0.492443\n",
      "batch 254 g_loss : 1.463701\n",
      "batch 255 d_loss : 0.509972\n",
      "batch 255 g_loss : 0.878375\n",
      "batch 256 d_loss : 0.453382\n",
      "batch 256 g_loss : 1.672811\n",
      "batch 257 d_loss : 0.422207\n",
      "batch 257 g_loss : 1.455279\n",
      "batch 258 d_loss : 0.530036\n",
      "batch 258 g_loss : 0.897438\n",
      "batch 259 d_loss : 0.496195\n",
      "batch 259 g_loss : 1.828410\n",
      "batch 260 d_loss : 0.585382\n",
      "batch 260 g_loss : 0.948263\n",
      "batch 261 d_loss : 0.530962\n",
      "batch 261 g_loss : 1.487496\n",
      "batch 262 d_loss : 0.547432\n",
      "batch 262 g_loss : 0.746577\n",
      "batch 263 d_loss : 0.575853\n",
      "batch 263 g_loss : 1.510520\n",
      "batch 264 d_loss : 0.573703\n",
      "batch 264 g_loss : 1.018899\n",
      "batch 265 d_loss : 0.446917\n",
      "batch 265 g_loss : 1.265338\n",
      "batch 266 d_loss : 0.504904\n",
      "batch 266 g_loss : 1.010125\n",
      "batch 267 d_loss : 0.450211\n",
      "batch 267 g_loss : 1.515333\n",
      "batch 268 d_loss : 0.496478\n",
      "batch 268 g_loss : 1.094056\n",
      "batch 269 d_loss : 0.491244\n",
      "batch 269 g_loss : 1.307332\n",
      "batch 270 d_loss : 0.504747\n",
      "batch 270 g_loss : 1.151079\n",
      "batch 271 d_loss : 0.582591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 271 g_loss : 0.918489\n",
      "batch 272 d_loss : 0.527755\n",
      "batch 272 g_loss : 1.268314\n",
      "batch 273 d_loss : 0.468476\n",
      "batch 273 g_loss : 1.588399\n",
      "batch 274 d_loss : 0.487079\n",
      "batch 274 g_loss : 0.941471\n",
      "batch 275 d_loss : 0.468743\n",
      "batch 275 g_loss : 1.553002\n",
      "batch 276 d_loss : 0.536337\n",
      "batch 276 g_loss : 0.975147\n",
      "batch 277 d_loss : 0.535105\n",
      "batch 277 g_loss : 1.390451\n",
      "batch 278 d_loss : 0.443892\n",
      "batch 278 g_loss : 1.115123\n",
      "batch 279 d_loss : 0.421680\n",
      "batch 279 g_loss : 1.577903\n",
      "batch 280 d_loss : 0.516056\n",
      "batch 280 g_loss : 0.786304\n",
      "batch 281 d_loss : 0.518448\n",
      "batch 281 g_loss : 1.690316\n",
      "batch 282 d_loss : 0.636974\n",
      "batch 282 g_loss : 0.981885\n",
      "batch 283 d_loss : 0.581746\n",
      "batch 283 g_loss : 1.355654\n",
      "batch 284 d_loss : 0.437106\n",
      "batch 284 g_loss : 1.270923\n",
      "batch 285 d_loss : 0.472065\n",
      "batch 285 g_loss : 1.297708\n",
      "batch 286 d_loss : 0.467554\n",
      "batch 286 g_loss : 1.413678\n",
      "batch 287 d_loss : 0.438006\n",
      "batch 287 g_loss : 1.309584\n",
      "batch 288 d_loss : 0.426302\n",
      "batch 288 g_loss : 1.428411\n",
      "batch 289 d_loss : 0.498009\n",
      "batch 289 g_loss : 1.402529\n",
      "batch 290 d_loss : 0.497410\n",
      "batch 290 g_loss : 1.308102\n",
      "batch 291 d_loss : 0.498620\n",
      "batch 291 g_loss : 1.175751\n",
      "batch 292 d_loss : 0.521344\n",
      "batch 292 g_loss : 1.157534\n",
      "batch 293 d_loss : 0.551902\n",
      "batch 293 g_loss : 0.941316\n",
      "batch 294 d_loss : 0.542315\n",
      "batch 294 g_loss : 1.173810\n",
      "batch 295 d_loss : 0.569308\n",
      "batch 295 g_loss : 1.292949\n",
      "batch 296 d_loss : 0.528794\n",
      "batch 296 g_loss : 1.060516\n",
      "batch 297 d_loss : 0.476547\n",
      "batch 297 g_loss : 1.038959\n",
      "batch 298 d_loss : 0.521923\n",
      "batch 298 g_loss : 1.031746\n",
      "batch 299 d_loss : 0.502153\n",
      "batch 299 g_loss : 0.883492\n",
      "batch 300 d_loss : 0.447408\n",
      "batch 300 g_loss : 1.379445\n",
      "batch 301 d_loss : 0.529337\n",
      "batch 301 g_loss : 0.942052\n",
      "batch 302 d_loss : 0.481171\n",
      "batch 302 g_loss : 1.329089\n",
      "batch 303 d_loss : 0.491561\n",
      "batch 303 g_loss : 1.191635\n",
      "batch 304 d_loss : 0.425961\n",
      "batch 304 g_loss : 1.349176\n",
      "batch 305 d_loss : 0.604914\n",
      "batch 305 g_loss : 0.939221\n",
      "batch 306 d_loss : 0.672981\n",
      "batch 306 g_loss : 1.174130\n",
      "batch 307 d_loss : 0.681967\n",
      "batch 307 g_loss : 0.853367\n",
      "batch 308 d_loss : 0.700017\n",
      "batch 308 g_loss : 1.248111\n",
      "batch 309 d_loss : 0.611918\n",
      "batch 309 g_loss : 0.849317\n",
      "batch 310 d_loss : 0.544282\n",
      "batch 310 g_loss : 1.182374\n",
      "batch 311 d_loss : 0.547340\n",
      "batch 311 g_loss : 0.875025\n",
      "batch 312 d_loss : 0.557796\n",
      "batch 312 g_loss : 1.156601\n",
      "batch 313 d_loss : 0.570886\n",
      "batch 313 g_loss : 0.891174\n",
      "batch 314 d_loss : 0.539089\n",
      "batch 314 g_loss : 1.306667\n",
      "batch 315 d_loss : 0.526038\n",
      "batch 315 g_loss : 0.930159\n",
      "batch 316 d_loss : 0.559195\n",
      "batch 316 g_loss : 1.005651\n",
      "batch 317 d_loss : 0.573457\n",
      "batch 317 g_loss : 1.060396\n",
      "batch 318 d_loss : 0.473154\n",
      "batch 318 g_loss : 1.046221\n",
      "batch 319 d_loss : 0.538168\n",
      "batch 319 g_loss : 1.024553\n",
      "batch 320 d_loss : 0.513676\n",
      "batch 320 g_loss : 1.153011\n",
      "batch 321 d_loss : 0.498112\n",
      "batch 321 g_loss : 1.314355\n",
      "batch 322 d_loss : 0.596199\n",
      "batch 322 g_loss : 0.972824\n",
      "batch 323 d_loss : 0.566406\n",
      "batch 323 g_loss : 1.148333\n",
      "batch 324 d_loss : 0.620607\n",
      "batch 324 g_loss : 0.738573\n",
      "batch 325 d_loss : 0.574586\n",
      "batch 325 g_loss : 1.318567\n",
      "batch 326 d_loss : 0.591948\n",
      "batch 326 g_loss : 0.666415\n",
      "batch 327 d_loss : 0.641042\n",
      "batch 327 g_loss : 1.398119\n",
      "batch 328 d_loss : 0.581909\n",
      "batch 328 g_loss : 1.023384\n",
      "batch 329 d_loss : 0.581490\n",
      "batch 329 g_loss : 0.932001\n",
      "batch 330 d_loss : 0.585632\n",
      "batch 330 g_loss : 0.898616\n",
      "batch 331 d_loss : 0.554981\n",
      "batch 331 g_loss : 1.375763\n",
      "batch 332 d_loss : 0.545866\n",
      "batch 332 g_loss : 1.088268\n",
      "batch 333 d_loss : 0.550120\n",
      "batch 333 g_loss : 1.065938\n",
      "batch 334 d_loss : 0.484220\n",
      "batch 334 g_loss : 1.604481\n",
      "batch 335 d_loss : 0.443056\n",
      "batch 335 g_loss : 1.192173\n",
      "batch 336 d_loss : 0.422485\n",
      "batch 336 g_loss : 1.274076\n",
      "batch 337 d_loss : 0.426545\n",
      "batch 337 g_loss : 1.207194\n",
      "batch 338 d_loss : 0.427871\n",
      "batch 338 g_loss : 1.324671\n",
      "batch 339 d_loss : 0.427940\n",
      "batch 339 g_loss : 1.382213\n",
      "batch 340 d_loss : 0.458168\n",
      "batch 340 g_loss : 1.046425\n",
      "batch 341 d_loss : 0.502307\n",
      "batch 341 g_loss : 1.186231\n",
      "batch 342 d_loss : 0.450079\n",
      "batch 342 g_loss : 1.444846\n",
      "batch 343 d_loss : 0.399994\n",
      "batch 343 g_loss : 1.356370\n",
      "batch 344 d_loss : 0.451152\n",
      "batch 344 g_loss : 1.065118\n",
      "batch 345 d_loss : 0.511080\n",
      "batch 345 g_loss : 1.344893\n",
      "batch 346 d_loss : 0.542759\n",
      "batch 346 g_loss : 1.154461\n",
      "batch 347 d_loss : 0.475828\n",
      "batch 347 g_loss : 1.166968\n",
      "batch 348 d_loss : 0.446072\n",
      "batch 348 g_loss : 1.292067\n",
      "batch 349 d_loss : 0.429811\n",
      "batch 349 g_loss : 1.389672\n",
      "batch 350 d_loss : 0.551655\n",
      "batch 350 g_loss : 1.217130\n",
      "batch 351 d_loss : 0.588967\n",
      "batch 351 g_loss : 1.036261\n",
      "batch 352 d_loss : 0.543288\n",
      "batch 352 g_loss : 1.120074\n",
      "batch 353 d_loss : 0.505506\n",
      "batch 353 g_loss : 1.327000\n",
      "batch 354 d_loss : 0.494929\n",
      "batch 354 g_loss : 1.216236\n",
      "batch 355 d_loss : 0.460652\n",
      "batch 355 g_loss : 1.168033\n",
      "batch 356 d_loss : 0.497081\n",
      "batch 356 g_loss : 1.337569\n",
      "batch 357 d_loss : 0.492796\n",
      "batch 357 g_loss : 1.213171\n",
      "batch 358 d_loss : 0.476736\n",
      "batch 358 g_loss : 1.260293\n",
      "batch 359 d_loss : 0.499943\n",
      "batch 359 g_loss : 0.890473\n",
      "batch 360 d_loss : 0.439878\n",
      "batch 360 g_loss : 1.736812\n",
      "batch 361 d_loss : 0.438406\n",
      "batch 361 g_loss : 1.176950\n",
      "batch 362 d_loss : 0.469765\n",
      "batch 362 g_loss : 1.467040\n",
      "batch 363 d_loss : 0.410957\n",
      "batch 363 g_loss : 1.150712\n",
      "batch 364 d_loss : 0.440455\n",
      "batch 364 g_loss : 1.369974\n",
      "batch 365 d_loss : 0.357945\n",
      "batch 365 g_loss : 1.438743\n",
      "batch 366 d_loss : 0.442725\n",
      "batch 366 g_loss : 1.285400\n",
      "batch 367 d_loss : 0.464301\n",
      "batch 367 g_loss : 1.205302\n",
      "batch 368 d_loss : 0.422472\n",
      "batch 368 g_loss : 1.721671\n",
      "batch 369 d_loss : 0.375613\n",
      "batch 369 g_loss : 1.292764\n",
      "batch 370 d_loss : 0.528827\n",
      "batch 370 g_loss : 1.284377\n",
      "batch 371 d_loss : 0.507822\n",
      "batch 371 g_loss : 1.342866\n",
      "batch 372 d_loss : 0.381722\n",
      "batch 372 g_loss : 1.822037\n",
      "batch 373 d_loss : 0.417672\n",
      "batch 373 g_loss : 1.313330\n",
      "batch 374 d_loss : 0.457942\n",
      "batch 374 g_loss : 1.316303\n",
      "batch 375 d_loss : 0.395088\n",
      "batch 375 g_loss : 1.674145\n",
      "batch 376 d_loss : 0.386985\n",
      "batch 376 g_loss : 1.423416\n",
      "batch 377 d_loss : 0.397349\n",
      "batch 377 g_loss : 1.581244\n",
      "batch 378 d_loss : 0.377344\n",
      "batch 378 g_loss : 1.326687\n",
      "batch 379 d_loss : 0.438800\n",
      "batch 379 g_loss : 1.380580\n",
      "batch 380 d_loss : 0.382166\n",
      "batch 380 g_loss : 1.644872\n",
      "batch 381 d_loss : 0.382685\n",
      "batch 381 g_loss : 1.397040\n",
      "batch 382 d_loss : 0.471869\n",
      "batch 382 g_loss : 1.018404\n",
      "batch 383 d_loss : 0.534392\n",
      "batch 383 g_loss : 1.121600\n",
      "batch 384 d_loss : 0.474841\n",
      "batch 384 g_loss : 1.460127\n",
      "batch 385 d_loss : 0.389661\n",
      "batch 385 g_loss : 1.446630\n",
      "batch 386 d_loss : 0.529037\n",
      "batch 386 g_loss : 1.139904\n",
      "batch 387 d_loss : 0.451823\n",
      "batch 387 g_loss : 1.446057\n",
      "batch 388 d_loss : 0.398170\n",
      "batch 388 g_loss : 1.467628\n",
      "batch 389 d_loss : 0.342572\n",
      "batch 389 g_loss : 1.976847\n",
      "batch 390 d_loss : 0.350378\n",
      "batch 390 g_loss : 1.365647\n",
      "batch 391 d_loss : 0.423440\n",
      "batch 391 g_loss : 1.434735\n",
      "batch 392 d_loss : 0.396927\n",
      "batch 392 g_loss : 1.697895\n",
      "batch 393 d_loss : 0.469134\n",
      "batch 393 g_loss : 1.088485\n",
      "batch 394 d_loss : 0.487297\n",
      "batch 394 g_loss : 1.595405\n",
      "batch 395 d_loss : 0.400951\n",
      "batch 395 g_loss : 1.524356\n",
      "batch 396 d_loss : 0.555984\n",
      "batch 396 g_loss : 1.182323\n",
      "batch 397 d_loss : 0.632947\n",
      "batch 397 g_loss : 1.415457\n",
      "batch 398 d_loss : 0.482475\n",
      "batch 398 g_loss : 1.164323\n",
      "batch 399 d_loss : 0.679864\n",
      "batch 399 g_loss : 1.211068\n",
      "batch 400 d_loss : 0.700363\n",
      "batch 400 g_loss : 0.791111\n",
      "batch 401 d_loss : 0.540779\n",
      "batch 401 g_loss : 2.180536\n",
      "batch 402 d_loss : 0.554092\n",
      "batch 402 g_loss : 0.653795\n",
      "batch 403 d_loss : 0.571090\n",
      "batch 403 g_loss : 2.673980\n",
      "batch 404 d_loss : 0.758987\n",
      "batch 404 g_loss : 0.415855\n",
      "batch 405 d_loss : 0.808333\n",
      "batch 405 g_loss : 3.336049\n",
      "batch 406 d_loss : 0.948197\n",
      "batch 406 g_loss : 0.457184\n",
      "batch 407 d_loss : 0.720192\n",
      "batch 407 g_loss : 2.282675\n",
      "batch 408 d_loss : 0.586810\n",
      "batch 408 g_loss : 0.868775\n",
      "batch 409 d_loss : 0.526418\n",
      "batch 409 g_loss : 2.100609\n",
      "batch 410 d_loss : 0.418200\n",
      "batch 410 g_loss : 1.736108\n",
      "batch 411 d_loss : 0.493816\n",
      "batch 411 g_loss : 1.060971\n",
      "batch 412 d_loss : 0.535038\n",
      "batch 412 g_loss : 1.634964\n",
      "batch 413 d_loss : 0.494013\n",
      "batch 413 g_loss : 1.492850\n",
      "batch 414 d_loss : 0.428586\n",
      "batch 414 g_loss : 1.563637\n",
      "batch 415 d_loss : 0.412140\n",
      "batch 415 g_loss : 1.393994\n",
      "batch 416 d_loss : 0.456519\n",
      "batch 416 g_loss : 1.306158\n",
      "batch 417 d_loss : 0.410410\n",
      "batch 417 g_loss : 1.233816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 418 d_loss : 0.411667\n",
      "batch 418 g_loss : 1.580013\n",
      "batch 419 d_loss : 0.340878\n",
      "batch 419 g_loss : 1.542480\n",
      "batch 420 d_loss : 0.302454\n",
      "batch 420 g_loss : 1.610459\n",
      "batch 421 d_loss : 0.289563\n",
      "batch 421 g_loss : 1.764639\n",
      "batch 422 d_loss : 0.366280\n",
      "batch 422 g_loss : 1.823069\n",
      "batch 423 d_loss : 0.278884\n",
      "batch 423 g_loss : 1.847920\n",
      "batch 424 d_loss : 0.329258\n",
      "batch 424 g_loss : 1.763125\n",
      "batch 425 d_loss : 0.398736\n",
      "batch 425 g_loss : 1.786752\n",
      "batch 426 d_loss : 0.378725\n",
      "batch 426 g_loss : 1.878575\n",
      "batch 427 d_loss : 0.486311\n",
      "batch 427 g_loss : 1.576686\n",
      "batch 428 d_loss : 0.382331\n",
      "batch 428 g_loss : 1.690217\n",
      "batch 429 d_loss : 0.433445\n",
      "batch 429 g_loss : 1.712208\n",
      "batch 430 d_loss : 0.359642\n",
      "batch 430 g_loss : 1.746453\n",
      "batch 431 d_loss : 0.425347\n",
      "batch 431 g_loss : 1.652702\n",
      "batch 432 d_loss : 0.392898\n",
      "batch 432 g_loss : 1.776468\n",
      "batch 433 d_loss : 0.512220\n",
      "batch 433 g_loss : 1.169250\n",
      "batch 434 d_loss : 0.624500\n",
      "batch 434 g_loss : 1.552957\n",
      "batch 435 d_loss : 0.589738\n",
      "batch 435 g_loss : 1.372002\n",
      "batch 436 d_loss : 0.391554\n",
      "batch 436 g_loss : 2.146629\n",
      "batch 437 d_loss : 0.492197\n",
      "batch 437 g_loss : 1.303375\n",
      "batch 438 d_loss : 0.477889\n",
      "batch 438 g_loss : 1.535087\n",
      "batch 439 d_loss : 0.549591\n",
      "batch 439 g_loss : 0.950192\n",
      "batch 440 d_loss : 0.617308\n",
      "batch 440 g_loss : 2.153518\n",
      "batch 441 d_loss : 0.786004\n",
      "batch 441 g_loss : 0.509586\n",
      "batch 442 d_loss : 0.790947\n",
      "batch 442 g_loss : 2.070954\n",
      "batch 443 d_loss : 0.707449\n",
      "batch 443 g_loss : 1.234859\n",
      "batch 444 d_loss : 0.630661\n",
      "batch 444 g_loss : 1.704399\n",
      "batch 445 d_loss : 0.638422\n",
      "batch 445 g_loss : 0.998074\n",
      "batch 446 d_loss : 0.518796\n",
      "batch 446 g_loss : 1.488470\n",
      "batch 447 d_loss : 0.461046\n",
      "batch 447 g_loss : 1.047997\n",
      "batch 448 d_loss : 0.494919\n",
      "batch 448 g_loss : 1.382738\n",
      "batch 449 d_loss : 0.416151\n",
      "batch 449 g_loss : 1.442727\n",
      "batch 450 d_loss : 0.392297\n",
      "batch 450 g_loss : 1.249462\n",
      "batch 451 d_loss : 0.401746\n",
      "batch 451 g_loss : 1.502192\n",
      "batch 452 d_loss : 0.443907\n",
      "batch 452 g_loss : 1.093987\n",
      "batch 453 d_loss : 0.422951\n",
      "batch 453 g_loss : 1.654113\n",
      "batch 454 d_loss : 0.325320\n",
      "batch 454 g_loss : 1.806624\n",
      "batch 455 d_loss : 0.402262\n",
      "batch 455 g_loss : 1.449055\n",
      "batch 456 d_loss : 0.426045\n",
      "batch 456 g_loss : 1.672858\n",
      "batch 457 d_loss : 0.298892\n",
      "batch 457 g_loss : 1.668679\n",
      "batch 458 d_loss : 0.236911\n",
      "batch 458 g_loss : 2.469239\n",
      "batch 459 d_loss : 0.327220\n",
      "batch 459 g_loss : 1.674188\n",
      "batch 460 d_loss : 0.365738\n",
      "batch 460 g_loss : 1.868797\n",
      "batch 461 d_loss : 0.278728\n",
      "batch 461 g_loss : 1.945567\n",
      "batch 462 d_loss : 0.410200\n",
      "batch 462 g_loss : 1.259176\n",
      "batch 463 d_loss : 0.711321\n",
      "batch 463 g_loss : 1.795871\n",
      "batch 464 d_loss : 0.765218\n",
      "batch 464 g_loss : 1.514420\n",
      "batch 465 d_loss : 0.317773\n",
      "batch 465 g_loss : 1.904568\n",
      "batch 466 d_loss : 0.461524\n",
      "batch 466 g_loss : 0.868138\n",
      "batch 467 d_loss : 0.498337\n",
      "batch 467 g_loss : 2.098224\n",
      "Epoch is 2\n",
      "Number of batches 468\n",
      "batch 0 d_loss : 0.405204\n",
      "batch 0 g_loss : 1.298805\n",
      "batch 1 d_loss : 0.416643\n",
      "batch 1 g_loss : 2.212200\n",
      "batch 2 d_loss : 0.410438\n",
      "batch 2 g_loss : 1.346262\n",
      "batch 3 d_loss : 0.422736\n",
      "batch 3 g_loss : 1.479281\n",
      "batch 4 d_loss : 0.415452\n",
      "batch 4 g_loss : 1.611537\n",
      "batch 5 d_loss : 0.442666\n",
      "batch 5 g_loss : 1.730177\n",
      "batch 6 d_loss : 0.434079\n",
      "batch 6 g_loss : 1.553347\n",
      "batch 7 d_loss : 0.451126\n",
      "batch 7 g_loss : 1.492612\n",
      "batch 8 d_loss : 0.513945\n",
      "batch 8 g_loss : 1.245265\n",
      "batch 9 d_loss : 0.459863\n",
      "batch 9 g_loss : 1.840267\n",
      "batch 10 d_loss : 0.379665\n",
      "batch 10 g_loss : 2.015329\n",
      "batch 11 d_loss : 0.520923\n",
      "batch 11 g_loss : 0.919209\n",
      "batch 12 d_loss : 0.481658\n",
      "batch 12 g_loss : 1.918945\n",
      "batch 13 d_loss : 0.378960\n",
      "batch 13 g_loss : 1.264147\n",
      "batch 14 d_loss : 0.370817\n",
      "batch 14 g_loss : 1.340654\n",
      "batch 15 d_loss : 0.382103\n",
      "batch 15 g_loss : 1.694615\n",
      "batch 16 d_loss : 0.373244\n",
      "batch 16 g_loss : 1.594464\n",
      "batch 17 d_loss : 0.307900\n",
      "batch 17 g_loss : 1.600779\n",
      "batch 18 d_loss : 0.400866\n",
      "batch 18 g_loss : 1.566714\n",
      "batch 19 d_loss : 0.354922\n",
      "batch 19 g_loss : 1.679330\n",
      "batch 20 d_loss : 0.300916\n",
      "batch 20 g_loss : 1.698334\n",
      "batch 21 d_loss : 0.339036\n",
      "batch 21 g_loss : 2.058991\n",
      "batch 22 d_loss : 0.433103\n",
      "batch 22 g_loss : 1.515901\n",
      "batch 23 d_loss : 0.330669\n",
      "batch 23 g_loss : 2.243163\n",
      "batch 24 d_loss : 0.319812\n",
      "batch 24 g_loss : 2.023950\n",
      "batch 25 d_loss : 0.367590\n",
      "batch 25 g_loss : 1.910499\n",
      "batch 26 d_loss : 0.308868\n",
      "batch 26 g_loss : 1.728885\n",
      "batch 27 d_loss : 0.350225\n",
      "batch 27 g_loss : 1.973372\n",
      "batch 28 d_loss : 0.447291\n",
      "batch 28 g_loss : 1.456172\n",
      "batch 29 d_loss : 0.329131\n",
      "batch 29 g_loss : 1.610261\n",
      "batch 30 d_loss : 0.348769\n",
      "batch 30 g_loss : 1.753687\n",
      "batch 31 d_loss : 0.418111\n",
      "batch 31 g_loss : 1.051112\n",
      "batch 32 d_loss : 0.444871\n",
      "batch 32 g_loss : 1.773600\n",
      "batch 33 d_loss : 0.403773\n",
      "batch 33 g_loss : 1.035748\n",
      "batch 34 d_loss : 0.405664\n",
      "batch 34 g_loss : 1.674443\n",
      "batch 35 d_loss : 0.458905\n",
      "batch 35 g_loss : 0.773442\n",
      "batch 36 d_loss : 0.547914\n",
      "batch 36 g_loss : 1.744172\n",
      "batch 37 d_loss : 0.513850\n",
      "batch 37 g_loss : 0.690200\n",
      "batch 38 d_loss : 0.486114\n",
      "batch 38 g_loss : 1.938765\n",
      "batch 39 d_loss : 0.444216\n",
      "batch 39 g_loss : 0.858081\n",
      "batch 40 d_loss : 0.439488\n",
      "batch 40 g_loss : 2.103422\n",
      "batch 41 d_loss : 0.495556\n",
      "batch 41 g_loss : 0.841566\n",
      "batch 42 d_loss : 0.484142\n",
      "batch 42 g_loss : 1.773426\n",
      "batch 43 d_loss : 0.371123\n",
      "batch 43 g_loss : 1.157948\n",
      "batch 44 d_loss : 0.311968\n",
      "batch 44 g_loss : 1.735323\n",
      "batch 45 d_loss : 0.325572\n",
      "batch 45 g_loss : 1.385384\n",
      "batch 46 d_loss : 0.383074\n",
      "batch 46 g_loss : 1.795266\n",
      "batch 47 d_loss : 0.396303\n",
      "batch 47 g_loss : 1.373374\n",
      "batch 48 d_loss : 0.346305\n",
      "batch 48 g_loss : 1.734572\n",
      "batch 49 d_loss : 0.321563\n",
      "batch 49 g_loss : 1.730078\n",
      "batch 50 d_loss : 0.299805\n",
      "batch 50 g_loss : 1.768661\n",
      "batch 51 d_loss : 0.240545\n",
      "batch 51 g_loss : 2.176419\n",
      "batch 52 d_loss : 0.274991\n",
      "batch 52 g_loss : 1.694103\n",
      "batch 53 d_loss : 0.312267\n",
      "batch 53 g_loss : 1.616218\n",
      "batch 54 d_loss : 0.240047\n",
      "batch 54 g_loss : 2.022397\n",
      "batch 55 d_loss : 0.216866\n",
      "batch 55 g_loss : 2.186389\n",
      "batch 56 d_loss : 0.272867\n",
      "batch 56 g_loss : 1.514405\n",
      "batch 57 d_loss : 0.273022\n",
      "batch 57 g_loss : 2.216768\n",
      "batch 58 d_loss : 0.193858\n",
      "batch 58 g_loss : 2.064570\n",
      "batch 59 d_loss : 0.243357\n",
      "batch 59 g_loss : 1.763108\n",
      "batch 60 d_loss : 0.251349\n",
      "batch 60 g_loss : 2.328609\n",
      "batch 61 d_loss : 0.391001\n",
      "batch 61 g_loss : 1.294066\n",
      "batch 62 d_loss : 0.405760\n",
      "batch 62 g_loss : 2.432044\n",
      "batch 63 d_loss : 0.274086\n",
      "batch 63 g_loss : 1.921897\n",
      "batch 64 d_loss : 0.243622\n",
      "batch 64 g_loss : 2.289623\n",
      "batch 65 d_loss : 0.301446\n",
      "batch 65 g_loss : 1.538399\n",
      "batch 66 d_loss : 0.518215\n",
      "batch 66 g_loss : 1.402586\n",
      "batch 67 d_loss : 0.374241\n",
      "batch 67 g_loss : 1.830048\n",
      "batch 68 d_loss : 0.308728\n",
      "batch 68 g_loss : 1.679608\n",
      "batch 69 d_loss : 0.335960\n",
      "batch 69 g_loss : 1.942206\n",
      "batch 70 d_loss : 0.349177\n",
      "batch 70 g_loss : 1.731387\n",
      "batch 71 d_loss : 0.397499\n",
      "batch 71 g_loss : 1.421374\n",
      "batch 72 d_loss : 0.503620\n",
      "batch 72 g_loss : 1.752441\n",
      "batch 73 d_loss : 0.435810\n",
      "batch 73 g_loss : 1.791913\n",
      "batch 74 d_loss : 0.621154\n",
      "batch 74 g_loss : 0.755287\n",
      "batch 75 d_loss : 0.559997\n",
      "batch 75 g_loss : 1.970239\n",
      "batch 76 d_loss : 0.426542\n",
      "batch 76 g_loss : 1.690343\n",
      "batch 77 d_loss : 0.408840\n",
      "batch 77 g_loss : 1.511650\n",
      "batch 78 d_loss : 0.403337\n",
      "batch 78 g_loss : 1.413330\n",
      "batch 79 d_loss : 0.659067\n",
      "batch 79 g_loss : 1.748853\n",
      "batch 80 d_loss : 0.885632\n",
      "batch 80 g_loss : 1.108220\n",
      "batch 81 d_loss : 0.570275\n",
      "batch 81 g_loss : 1.726579\n",
      "batch 82 d_loss : 0.468788\n",
      "batch 82 g_loss : 1.345114\n",
      "batch 83 d_loss : 0.474812\n",
      "batch 83 g_loss : 1.492949\n",
      "batch 84 d_loss : 0.516941\n",
      "batch 84 g_loss : 1.201222\n",
      "batch 85 d_loss : 0.578654\n",
      "batch 85 g_loss : 1.550301\n",
      "batch 86 d_loss : 0.568320\n",
      "batch 86 g_loss : 1.394271\n",
      "batch 87 d_loss : 0.433124\n",
      "batch 87 g_loss : 1.590058\n",
      "batch 88 d_loss : 0.472205\n",
      "batch 88 g_loss : 1.205693\n",
      "batch 89 d_loss : 0.473308\n",
      "batch 89 g_loss : 1.677377\n",
      "batch 90 d_loss : 0.519856\n",
      "batch 90 g_loss : 0.947680\n",
      "batch 91 d_loss : 0.535178\n",
      "batch 91 g_loss : 2.217571\n",
      "batch 92 d_loss : 0.487946\n",
      "batch 92 g_loss : 0.914951\n",
      "batch 93 d_loss : 0.510964\n",
      "batch 93 g_loss : 2.088809\n",
      "batch 94 d_loss : 0.479700\n",
      "batch 94 g_loss : 1.068480\n",
      "batch 95 d_loss : 0.484007\n",
      "batch 95 g_loss : 2.161126\n",
      "batch 96 d_loss : 0.524533\n",
      "batch 96 g_loss : 0.788707\n",
      "batch 97 d_loss : 0.633997\n",
      "batch 97 g_loss : 3.184485\n",
      "batch 98 d_loss : 0.608848\n",
      "batch 98 g_loss : 0.721285\n",
      "batch 99 d_loss : 0.523235\n",
      "batch 99 g_loss : 2.692553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 100 d_loss : 0.508856\n",
      "batch 100 g_loss : 0.657094\n",
      "batch 101 d_loss : 0.688800\n",
      "batch 101 g_loss : 2.557090\n",
      "batch 102 d_loss : 0.558131\n",
      "batch 102 g_loss : 0.923550\n",
      "batch 103 d_loss : 0.407503\n",
      "batch 103 g_loss : 2.474998\n",
      "batch 104 d_loss : 0.364268\n",
      "batch 104 g_loss : 1.392776\n",
      "batch 105 d_loss : 0.331237\n",
      "batch 105 g_loss : 2.363018\n",
      "batch 106 d_loss : 0.442097\n",
      "batch 106 g_loss : 0.677369\n",
      "batch 107 d_loss : 0.530164\n",
      "batch 107 g_loss : 2.934262\n",
      "batch 108 d_loss : 0.467695\n",
      "batch 108 g_loss : 1.056248\n",
      "batch 109 d_loss : 0.393472\n",
      "batch 109 g_loss : 2.199952\n",
      "batch 110 d_loss : 0.349373\n",
      "batch 110 g_loss : 1.699593\n",
      "batch 111 d_loss : 0.340389\n",
      "batch 111 g_loss : 1.577768\n",
      "batch 112 d_loss : 0.349974\n",
      "batch 112 g_loss : 1.732228\n",
      "batch 113 d_loss : 0.375946\n",
      "batch 113 g_loss : 1.099101\n",
      "batch 114 d_loss : 0.390269\n",
      "batch 114 g_loss : 2.545557\n",
      "batch 115 d_loss : 0.411453\n",
      "batch 115 g_loss : 1.069388\n",
      "batch 116 d_loss : 0.393594\n",
      "batch 116 g_loss : 1.717600\n",
      "batch 117 d_loss : 0.409206\n",
      "batch 117 g_loss : 1.016407\n",
      "batch 118 d_loss : 0.408987\n",
      "batch 118 g_loss : 2.026187\n",
      "batch 119 d_loss : 0.431279\n",
      "batch 119 g_loss : 1.050851\n",
      "batch 120 d_loss : 0.441519\n",
      "batch 120 g_loss : 2.075856\n",
      "batch 121 d_loss : 0.449665\n",
      "batch 121 g_loss : 0.919479\n",
      "batch 122 d_loss : 0.465501\n",
      "batch 122 g_loss : 2.208968\n",
      "batch 123 d_loss : 0.440869\n",
      "batch 123 g_loss : 0.979857\n",
      "batch 124 d_loss : 0.587671\n",
      "batch 124 g_loss : 1.280789\n",
      "batch 125 d_loss : 0.616618\n",
      "batch 125 g_loss : 1.180615\n",
      "batch 126 d_loss : 0.572149\n",
      "batch 126 g_loss : 1.495141\n",
      "batch 127 d_loss : 0.473706\n",
      "batch 127 g_loss : 1.130215\n",
      "batch 128 d_loss : 0.463934\n",
      "batch 128 g_loss : 1.637454\n",
      "batch 129 d_loss : 0.404647\n",
      "batch 129 g_loss : 1.105077\n",
      "batch 130 d_loss : 0.488875\n",
      "batch 130 g_loss : 1.476911\n",
      "batch 131 d_loss : 0.393312\n",
      "batch 131 g_loss : 1.163720\n",
      "batch 132 d_loss : 0.510782\n",
      "batch 132 g_loss : 1.080988\n",
      "batch 133 d_loss : 0.468743\n",
      "batch 133 g_loss : 1.561955\n",
      "batch 134 d_loss : 0.432679\n",
      "batch 134 g_loss : 1.362678\n",
      "batch 135 d_loss : 0.407672\n",
      "batch 135 g_loss : 1.421561\n",
      "batch 136 d_loss : 0.431571\n",
      "batch 136 g_loss : 1.265338\n",
      "batch 137 d_loss : 0.428439\n",
      "batch 137 g_loss : 1.212612\n",
      "batch 138 d_loss : 0.441671\n",
      "batch 138 g_loss : 1.679317\n",
      "batch 139 d_loss : 0.471323\n",
      "batch 139 g_loss : 0.691667\n",
      "batch 140 d_loss : 0.513105\n",
      "batch 140 g_loss : 2.936765\n",
      "batch 141 d_loss : 0.612880\n",
      "batch 141 g_loss : 0.587429\n",
      "batch 142 d_loss : 0.593104\n",
      "batch 142 g_loss : 2.576391\n",
      "batch 143 d_loss : 0.532648\n",
      "batch 143 g_loss : 0.568977\n",
      "batch 144 d_loss : 0.575758\n",
      "batch 144 g_loss : 2.789491\n",
      "batch 145 d_loss : 0.418778\n",
      "batch 145 g_loss : 1.067990\n",
      "batch 146 d_loss : 0.359706\n",
      "batch 146 g_loss : 2.159534\n",
      "batch 147 d_loss : 0.345849\n",
      "batch 147 g_loss : 1.425678\n",
      "batch 148 d_loss : 0.296428\n",
      "batch 148 g_loss : 2.156836\n",
      "batch 149 d_loss : 0.281969\n",
      "batch 149 g_loss : 1.397114\n",
      "batch 150 d_loss : 0.335551\n",
      "batch 150 g_loss : 1.909279\n",
      "batch 151 d_loss : 0.359574\n",
      "batch 151 g_loss : 1.315101\n",
      "batch 152 d_loss : 0.416458\n",
      "batch 152 g_loss : 1.572800\n",
      "batch 153 d_loss : 0.321112\n",
      "batch 153 g_loss : 1.795568\n",
      "batch 154 d_loss : 0.272255\n",
      "batch 154 g_loss : 1.711190\n",
      "batch 155 d_loss : 0.336833\n",
      "batch 155 g_loss : 1.319798\n",
      "batch 156 d_loss : 0.349557\n",
      "batch 156 g_loss : 1.705469\n",
      "batch 157 d_loss : 0.284901\n",
      "batch 157 g_loss : 1.839058\n",
      "batch 158 d_loss : 0.309388\n",
      "batch 158 g_loss : 1.780239\n",
      "batch 159 d_loss : 0.256623\n",
      "batch 159 g_loss : 1.909267\n",
      "batch 160 d_loss : 0.276654\n",
      "batch 160 g_loss : 1.722964\n",
      "batch 161 d_loss : 0.293365\n",
      "batch 161 g_loss : 1.789902\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b12e920899c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-15eec0321f96>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(BATCH_SIZE)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[1;31m#生成的图片使用生成器对随机噪声进行推断；verbose为日志显示，0为不在标准输出流输出日志信息，1为输出进度条记录\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mgenerated_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;31m#每经过100次迭代输出一张生成的图片\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\software\\python\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m    911\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 913\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\software\\python\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1711\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1712\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[1;32m-> 1713\u001b[1;33m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[0;32m   1714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1715\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mf:\\software\\python\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[1;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1267\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1269\u001b[1;33m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1270\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\software\\python\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2273\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\software\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\software\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\software\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\software\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\software\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "跑30次迭代每次有400多batch时间太长，所以在第一个100处保存了就先退出了。\n",
    "\n",
    "但是看了下下面生成的效果不好，还是再继续跑跑吧..吃饭去了先"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(BATCH_SIZE, nice= False ):\n",
    "    #训练完模型后，可以运行该函数生成图片\n",
    "    g = generator_model()\n",
    "    g.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    g.load_weights('generator')\n",
    "    if nice:\n",
    "        d = discriminator_model()\n",
    "        d.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "        d.load_weights('discriminator')\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE*20, 100))\n",
    "        generated_images = g.predict(noise, verbose=1)\n",
    "        d_pret = d.predict(generated_images, verbose=1)\n",
    "        index = np.arange(0, BATCH_SIZE*20)\n",
    "        index.resize((BATCH_SIZE*20, 1))\n",
    "        pre_with_index = list(np.append(d_pret, index, axis=1))\n",
    "        pre_with_index.sort(key=lambda x: x[0], reverse=True)\n",
    "        nice_images = np.zeros((BATCH_SIZE,) + generated_images.shape[1:3], dtype=np.float32)\n",
    "        nice_images = nice_images[:, :, :, None]\n",
    "        for i in range(BATCH_SIZE):\n",
    "            idx = int(pre_with_index[i][1])\n",
    "            nice_images[i, :, :, 0] = generated_images[idx, :, :, 0]\n",
    "        image = combine_images(nice_images)\n",
    "    else:\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
    "        generated_images = g.predict(noise, verbose=0)\n",
    "        image = combine_images(generated_images)\n",
    "    image = image*127.5+127.5\n",
    "    Image.fromarray(image.astype(np.uint8)).save(\"./MNIST_data/generated_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\software\\python\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1024, input_dim=100)`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "generate(128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "初始：\n",
    "![start](./data/0_0.png)\n",
    "\n",
    "没跑完，结果还是可以看出一个大致的轮廓：\n",
    "\n",
    "![result](./data/2_100.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
